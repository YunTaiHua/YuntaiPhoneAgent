"""
TTSæ–‡æœ¬å¤„ç†å™¨ - è´Ÿè´£TTSæ–‡æœ¬æ¸…æ´—ã€åˆ†æ®µé€»è¾‘
"""

import re


class TTSTextProcessor:
    """TTSæ–‡æœ¬å¤„ç†å™¨"""

    def __init__(self, max_text_length: int = 500):
        """
        åˆå§‹åŒ–æ–‡æœ¬å¤„ç†å™¨

        Args:
            max_text_length: å•ä¸ªæ–‡æœ¬ç‰‡æ®µæœ€å¤§é•¿åº¦
        """
        self.max_text_length = max_text_length

    def clean_text_for_tts(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ï¼Œä½†ä¸ä¸¢å¤±å¼€å¤´éƒ¨åˆ†"""
        if not text:
            return "ä½ å¥½ï¼Œæˆ‘æ˜¯å°èŠ¸ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡"

        # ä¿å­˜åŸå§‹æ–‡æœ¬ä»¥ä¾¿åç»­å¤„ç†
        original_text = text

        # 1. ç§»é™¤ä»£ç å—æ ‡è®°
        text = re.sub(r'```[a-zA-Z]*\n?', '', text)
        text = re.sub(r'```', '', text)

        # 2. ç§»é™¤URLå’Œç‰¹æ®Šæ ‡è®°ï¼Œä½†ä¿ç•™ä¸­æ–‡æ ‡ç‚¹
        text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)
        text = re.sub(r'\[.*?\]', '', text)  # ç§»é™¤æ–¹æ‹¬å·å†…å®¹

        # 3. ä¿ç•™ä¸­æ–‡æ ‡ç‚¹ï¼šï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š"'
        text = re.sub(r'[^\w\u4e00-\u9fff\s\.,ï¼Œã€‚!ï¼?ï¼Ÿ:ï¼š;ï¼›ã€\'\"\(\)ï¼ˆï¼‰ã€Šã€‹ã€ã€‘\-]', '', text)

        # 4. ç§»é™¤å¤šä½™ç©ºæ ¼ï¼Œä½†ä¿ç•™ä¸€ä¸ªç©ºæ ¼
        text = ' '.join(text.split())

        # 5. æ£€æŸ¥æ¸…ç†åçš„æ–‡æœ¬é•¿åº¦
        cleaned_text = text.strip()

        # æ£€æŸ¥æ˜¯å¦ä¸»è¦æ˜¯è‹±æ–‡æˆ–ç‰¹æ®Šå­—ç¬¦
        chinese_char_count = len([c for c in cleaned_text if '\u4e00' <= c <= '\u9fff'])
        total_char_count = len(cleaned_text)

        # å¦‚æœä¸­æ–‡å­—ç¬¦å æ¯”å¤ªä½æˆ–æ–‡æœ¬å¤ªçŸ­ï¼Œä½¿ç”¨å…œåº•æ–‡æœ¬
        if total_char_count == 0 or (total_char_count > 0 and chinese_char_count / total_char_count < 0.1) or len(cleaned_text) < 2:
            print(f"âš ï¸  æ¸…ç†åçš„æ–‡æœ¬è´¨é‡ä¸ä½³ï¼ˆä¸­æ–‡å­—ç¬¦å æ¯”: {chinese_char_count}/{total_char_count}ï¼‰ï¼Œä½¿ç”¨å…œåº•æ–‡æœ¬")
            # ä½¿ç”¨æ›´é•¿çš„å…œåº•æ–‡æœ¬ï¼Œç¡®ä¿GPT-SoVITSèƒ½æ­£å¸¸å¤„ç†
            return "ä½ å¥½ï¼Œæˆ‘æ˜¯å°èŠ¸ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡"

        return cleaned_text

    def should_use_segmented_synthesis(self, text: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨åˆ†æ®µåˆæˆ

        Args:
            text: è¦åˆ¤æ–­çš„æ–‡æœ¬

        Returns:
            Trueå¦‚æœåº”è¯¥ä½¿ç”¨åˆ†æ®µåˆæˆ
        """
        if not text:
            return False

        cleaned_text = self.clean_text_for_tts(text)

        # æ–‡æœ¬é•¿åº¦è¶…è¿‡é˜ˆå€¼
        if len(cleaned_text) > self.max_text_length * 1.5:  # è¶…è¿‡750å­—ç¬¦
            return True

        # åŒ…å«å¤šä¸ªåºå·æ®µè½
        numbered_patterns = [r'\d+\.\s', r'\d+ã€\s', r'\(\d+\)\s']
        for pattern in numbered_patterns:
            if len(re.findall(pattern, cleaned_text)) >= 2:
                return True

        return False

    def split_text_by_numbered_sections(self, text: str) -> list[str]:
        """
        æŒ‰åºå·åˆ†æ®µæ–‡æœ¬ï¼ˆæ”¹è¿›ç‰ˆï¼‰

        Args:
            text: è¦åˆ†æ®µçš„æ–‡æœ¬

        Returns:
            åˆ†æ®µåçš„æ–‡æœ¬åˆ—è¡¨
        """
        segments = []

        # å¤šç§åºå·æ¨¡å¼ï¼ˆä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼‰
        patterns = [
            (r'### (\d+\.)', 3),  # Markdownä¸‰çº§æ ‡é¢˜
            (r'## (\d+\.)', 2),  # MarkdownäºŒçº§æ ‡é¢˜
            (r'(\d+\.\s)', 1),  # æ•°å­—åŠ ç‚¹ï¼ˆè‹±æ–‡ï¼‰
            (r'(\d+ã€\s)', 1),  # æ•°å­—åŠ é¡¿å·ï¼ˆä¸­æ–‡ï¼‰
            (r'\((\d+)\)\s', 1),  # æ‹¬å·æ•°å­—
            (r'ä¸€ã€', 1),  # ä¸­æ–‡åºå·
            (r'äºŒã€', 1),
            (r'ä¸‰ã€', 1),
            (r'å››ã€', 1),
            (r'äº”ã€', 1),
            (r'é¦–å…ˆ', 1),  # è¿æ¥è¯
            (r'å…¶æ¬¡', 1),
            (r'å†æ¬¡', 1),
            (r'æœ€å', 1),
        ]

        best_pattern = None
        best_matches = []

        # å¯»æ‰¾æœ€ä½³åˆ†æ®µæ¨¡å¼
        for pattern, priority in patterns:
            matches = list(re.finditer(pattern, text))
            if len(matches) >= 2:  # è‡³å°‘æœ‰2ä¸ªåŒ¹é…
                if not best_matches or (
                len(matches) > len(best_matches) and priority >= patterns[patterns.index((best_pattern, 0))][
                    1] if best_pattern else 0):
                    best_pattern = pattern
                    best_matches = matches

        # ä½¿ç”¨æœ€ä½³æ¨¡å¼åˆ†æ®µ
        if best_pattern and best_matches:
            # ä»ç¬¬ä¸€ä¸ªåˆ†æ®µç‚¹å¼€å§‹
            start_pos = 0
            last_end_pos = 0

            for i, match in enumerate(best_matches):
                if i == 0:
                    # ç¬¬ä¸€æ®µï¼šä»å¼€å¤´åˆ°ç¬¬ä¸€ä¸ªåˆ†æ®µç‚¹
                    segment = text[start_pos:match.start()].strip()
                    if segment and len(segment) > 10:  # ç¡®ä¿ä¸æ˜¯ç©ºæ®µ
                        segments.append(segment)
                    start_pos = match.start()
                    last_end_pos = match.start()
                    continue

                # ä¸­é—´æ®µï¼šä»å‰ä¸€ä¸ªåˆ†æ®µç‚¹åˆ°å½“å‰åˆ†æ®µç‚¹
                segment = text[last_end_pos:match.start()].strip()
                if segment and len(segment) > 10:
                    segments.append(segment)
                last_end_pos = match.start()

            # æœ€åä¸€æ®µï¼šä»æœ€åä¸€ä¸ªåˆ†æ®µç‚¹åˆ°ç»“å°¾
            last_segment = text[last_end_pos:].strip()
            if last_segment and len(last_segment) > 10:
                segments.append(last_segment)

            # æ£€æŸ¥åˆ†æ®µè´¨é‡
            if segments and len(segments) >= 2:
                avg_length = sum(len(s) for s in segments) / len(segments)
                if 50 <= avg_length <= self.max_text_length * 2:
                    return segments
                else:
                    segments = []

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„åºå·åˆ†æ®µï¼Œå°è¯•æŒ‰æ®µè½åˆ†æ®µ
        if not segments:
            # æŒ‰ç©ºè¡Œåˆ†æ®µ
            paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
            if len(paragraphs) >= 2:
                # åˆå¹¶è¿‡çŸ­çš„æ®µè½
                merged = []
                buffer = ""

                for para in paragraphs:
                    if len(buffer) + len(para) < self.max_text_length:
                        if buffer:
                            buffer += "\n\n" + para
                        else:
                            buffer = para
                    else:
                        if buffer:
                            merged.append(buffer)
                        buffer = para

                if buffer:
                    merged.append(buffer)

                if len(merged) >= 2:
                    return merged

        # æœ€åå°è¯•æŒ‰æ ‡ç‚¹åˆ†æ®µ
        if not segments:
            segments = self.split_text_by_punctuation(text)

        return segments

    def split_text_by_punctuation(self, text: str) -> list[str]:
        """
        æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†æ®µ

        Args:
            text: è¦åˆ†æ®µçš„æ–‡æœ¬

        Returns:
            åˆ†æ®µåçš„æ–‡æœ¬åˆ—è¡¨
        """
        segments = []
        current_segment = ""

        # æ ‡ç‚¹ç¬¦å·åˆ—è¡¨
        punctuation_marks = ['ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼›', '.', '!', '?', ';']

        for char in text:
            current_segment += char

            # å¦‚æœé‡åˆ°æ ‡ç‚¹ï¼Œå¹¶ä¸”å½“å‰æ®µè¾¾åˆ°ä¸€å®šé•¿åº¦
            if char in punctuation_marks and len(current_segment) >= 50:
                segments.append(current_segment.strip())
                current_segment = ""

            # å¦‚æœå½“å‰æ®µè¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œå¼ºåˆ¶åˆ†æ®µ
            elif len(current_segment) >= self.max_text_length:
                # åœ¨æœ€åå‡ºç°çš„æ ‡ç‚¹å¤„åˆ†æ®µ
                last_punct = -1
                for punct in punctuation_marks:
                    pos = current_segment.rfind(punct)
                    if pos > last_punct:
                        last_punct = pos

                if last_punct > 0:
                    segments.append(current_segment[:last_punct + 1].strip())
                    current_segment = current_segment[last_punct + 1:]
                else:
                    # æ²¡æœ‰æ ‡ç‚¹ï¼ŒæŒ‰é•¿åº¦ç¡¬åˆ‡
                    segments.append(current_segment.strip())
                    current_segment = ""

        # æ·»åŠ æœ€åä¸€æ®µ
        if current_segment.strip():
            segments.append(current_segment.strip())

        # åˆå¹¶è¿‡çŸ­çš„æ®µè½
        merged_segments = []
        buffer = ""

        for segment in segments:
            if len(buffer) + len(segment) < self.max_text_length * 0.7:
                buffer += " " + segment if buffer else segment
            else:
                if buffer:
                    merged_segments.append(buffer)
                buffer = segment

        if buffer:
            merged_segments.append(buffer)

        #print(f"ğŸ“ æŒ‰æ ‡ç‚¹åˆ†æ®µï¼Œåˆå¹¶å: {len(merged_segments)} æ®µ")
        return merged_segments
