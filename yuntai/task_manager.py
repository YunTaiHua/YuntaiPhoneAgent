"""
TaskManager - ä»»åŠ¡è°ƒåº¦å’Œæ‰§è¡Œæ¨¡å—
è´Ÿè´£æ‰€æœ‰åå°ä»»åŠ¡çš„è°ƒåº¦ã€æ‰§è¡Œå’Œç®¡ç†
"""

import os
import sys
import threading
import time
import datetime
import traceback
import queue
from typing import Optional, Dict, Any, Tuple, List, Callable
import warnings
import logging
import pyaudio
import torch
import soundfile as sf
import re
import wave
from concurrent.futures import ThreadPoolExecutor, as_completed

logger = logging.getLogger(__name__)

# å¸¸é‡å®šä¹‰
DEFAULT_TTS_CONFIG_KEY = "default_tts_config"
SIMILARITY_THRESHOLD = 0.6
MIN_CHINESE_RATIO = 0.3
MAX_LIST_LENGTH = 50
AUDIO_CHUNK_SIZE = 1024
AUDIO_FORMAT_WIDTH = 2
AUDIO_CHANNELS = 1
DEFAULT_SAMPLE_RATE = 22050

# ç¬¬ä¸‰æ–¹åº“
from zhipuai import ZhipuAI

# é¡¹ç›®æ¨¡å—
from yuntai.connection_manager import ConnectionManager
from yuntai.file_manager import FileManager
from yuntai.task_recognizer import TaskRecognizer
from yuntai.agent_executor import AgentExecutor
from yuntai.utils import Utils
from yuntai.reply_manager import SmartContinuousReplyManager

# ä½¿ç”¨æ–°çš„ç»Ÿä¸€é…ç½®
from .config import (
    GPT_SOVITS_ROOT,
    GPT_MODEL_DIR,
    SOVITS_MODEL_DIR,
    REF_AUDIO_ROOT,
    REF_TEXT_ROOT,
    BERT_MODEL_PATH,
    HUBERT_MODEL_PATH,
    TTS_OUTPUT_DIR,
    ZHIPU_API_KEY,
    MAX_HISTORY_LENGTH,
    MAX_CYCLE_TIMES,
    MAX_RETRY_TIMES,
    WAIT_INTERVAL,
    TTS_REF_LANGUAGE,
    TTS_TARGET_LANGUAGE,
    SHORTCUTS,
    TTS_MAX_SEGMENT_LENGTH,
    TTS_MIN_TEXT_LENGTH,
    TTS_TOP_P,
    TTS_TEMPERATURE,
    TTS_SPEED,
    ZHIPU_CHAT_MODEL
)


class TTSManager:
    """TTSç®¡ç†å™¨ï¼šç»Ÿä¸€ç®¡ç†æ‰€æœ‰TTSç›¸å…³åŠŸèƒ½"""

    def __init__(self, project_root: str):
        """
        åˆå§‹åŒ–TTSç®¡ç†å™¨

        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
        """
        self.project_root = project_root

        # ä½¿ç”¨ç»Ÿä¸€é…ç½®
        self.gpt_sovits_root = GPT_SOVITS_ROOT
        self.bert_model_path = BERT_MODEL_PATH
        self.hubert_model_path = HUBERT_MODEL_PATH

        # é»˜è®¤TTSé…ç½®
        self.default_tts_config = {
            "gpt_model_dir": GPT_MODEL_DIR,
            "sovits_model_dir": SOVITS_MODEL_DIR,
            "ref_audio_root": REF_AUDIO_ROOT,
            "ref_text_root": REF_TEXT_ROOT,
            "ref_language": TTS_REF_LANGUAGE,
            "target_language": TTS_TARGET_LANGUAGE,
            "output_path": TTS_OUTPUT_DIR
        }


        # çŠ¶æ€å˜é‡
        self.tts_enabled = False
        self.tts_available = False
        self.tts_modules_loaded = False

        # çº¿ç¨‹å®‰å…¨çš„çŠ¶æ€å˜é‡
        self.is_tts_synthesizing = False
        self.is_tts_synthesizing_lock = threading.Lock()
        self.is_playing_audio = False
        self.is_playing_audio_lock = threading.Lock()
        self.tts_synthesized_files = []
        self.tts_synthesized_files_lock = threading.Lock()
        self.current_models_lock = threading.Lock()

        # å½“å‰é€‰ä¸­çš„æ¨¡å‹
        self.current_gpt_model = None
        self.current_sovits_model = None
        self.current_ref_audio = None
        self.current_ref_text = None

        # TTSæ¨¡å—
        self.tts_modules: Dict[str, Any] = {}

        # éŸ³é¢‘æ’­æ”¾å™¨
        self.audio_player = None
        self.audio_play_lock = threading.Lock()

        # çº¿ç¨‹æ± æ‰§è¡Œå™¨
        self.executor = ThreadPoolExecutor(max_workers=3)

        # TTSæ–‡ä»¶æ•°æ®åº“
        self.tts_files_database = {
            "gpt": {},  # {æ–‡ä»¶å: æ­£ç¡®ç»å¯¹è·¯å¾„}
            "sovits": {},  # {æ–‡ä»¶å: æ­£ç¡®ç»å¯¹è·¯å¾„}
            "audio": {},  # {æ–‡ä»¶å: æ­£ç¡®ç»å¯¹è·¯å¾„}
            "text": {}  # {æ–‡ä»¶å: æ­£ç¡®ç»å¯¹è·¯å¾„}
        }

        # ç¼“å­˜
        self._text_cache = {}  # {æ–‡ä»¶è·¯å¾„: æ–‡æœ¬å†…å®¹}
        self._cache_lock = threading.Lock()

        # è¿‡æ»¤å†—ä½™è­¦å‘Š
        warnings.filterwarnings('ignore')

        # åˆå§‹åŒ–éŸ³é¢‘æ’­æ”¾å™¨
        self._init_audio_player()

        # æ–°å¢ï¼šåˆ†æ®µåˆæˆç›¸å…³
        self.max_text_length = TTS_MAX_SEGMENT_LENGTH  # å•ä¸ªæ–‡æœ¬ç‰‡æ®µæœ€å¤§é•¿åº¦
        self.tts_segments = []  # å­˜å‚¨åˆ†æ®µéŸ³é¢‘è·¯å¾„
        self.tts_segments_lock = threading.Lock()

        # æ£€æŸ¥éŸ³é¢‘åˆå¹¶ä¾èµ–
        self.can_merge_audio = self._check_merge_dependencies()

    def _check_merge_dependencies(self) -> bool:
        """æ£€æŸ¥éŸ³é¢‘åˆå¹¶æ‰€éœ€çš„ä¾èµ–"""
        try:
            import numpy
            import soundfile
            return True
        except ImportError:
            logger.warning("éŸ³é¢‘åˆå¹¶åŠŸèƒ½éœ€è¦é¢å¤–ä¾èµ–: pip install numpy soundfile")
            return False

    def _get_cached_text(self, file_path: str) -> str:
        """è·å–ç¼“å­˜çš„æ–‡æœ¬å†…å®¹"""
        with self._cache_lock:
            if file_path in self._text_cache:
                return self._text_cache[file_path]
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                self._text_cache[file_path] = content
                return content
            except IOError as e:
                logger.error(f"è¯»å–æ–‡æœ¬æ–‡ä»¶å¤±è´¥: {file_path}, {e}")
                raise

    def synthesize_long_text_serial(self, text: str, ref_audio_path: str, ref_text_path: str) -> tuple[bool, str]:
        """
        åˆ†æ®µä¸²è¡Œåˆæˆé•¿æ–‡æœ¬è¯­éŸ³

        Args:
            text: è¦åˆæˆçš„é•¿æ–‡æœ¬
            ref_audio_path: å‚è€ƒéŸ³é¢‘è·¯å¾„
            ref_text_path: å‚è€ƒæ–‡æœ¬è·¯å¾„

        Returns:
            (success, æœ€ç»ˆéŸ³é¢‘æ–‡ä»¶è·¯å¾„)
        """
        try:
            # print(f"ğŸ“ å¼€å§‹åˆ†æ®µå¤„ç†æ–‡æœ¬ï¼Œæ€»é•¿åº¦: {len(text)} å­—ç¬¦")

            # æ¸…ç†æ–‡æœ¬
            cleaned_text = self._clean_text_for_tts(text)

            # åˆ†æ®µæ–‡æœ¬
            segments = self._split_text_by_numbered_sections(cleaned_text)

            if len(segments) == 1:
                # print(f"ğŸ“ æ–‡æœ¬è¾ƒçŸ­ï¼Œä½¿ç”¨å•æ¬¡åˆæˆ")
                # ç›´æ¥åˆæˆ
                return self.synthesize_text(text, ref_audio_path, ref_text_path, auto_play=False)

            # print(f"ğŸ“ æ–‡æœ¬åˆ†ä¸º {len(segments)} ä¸ªæ®µè½è¿›è¡Œä¸²è¡Œåˆæˆ")

            # ä¸²è¡Œåˆæˆæ¯ä¸ªåˆ†æ®µ
            segment_files = []

            for i, segment in enumerate(segments):
                # print(f"ğŸµ å¼€å§‹åˆæˆç¬¬ {i + 1}/{len(segments)} æ®µï¼Œé•¿åº¦: {len(segment)} å­—ç¬¦")

                # ä½¿ç”¨å¸¦é‡è¯•çš„åˆæˆ
                success, result = self.synthesize_text_with_retry(
                    segment, ref_audio_path, ref_text_path, max_retries=1
                )

                if success:
                    # print(f"âœ… ç¬¬ {i + 1} æ®µåˆæˆæˆåŠŸ: {os.path.basename(result)}")
                    segment_files.append((i, result))

                    # æ·»åŠ å»¶è¿Ÿé¿å…å†²çª
                    if i < len(segments) - 1:
                        time.sleep(0.3)  # 300mså»¶è¿Ÿ
                else:
                    print(f"âŒ ç¬¬ {i + 1} æ®µåˆæˆå¤±è´¥: {result}")
                    # å°è¯•ç”¨æ›´çŸ­çš„æ–‡æœ¬é‡è¯•
                    if len(segment) > 100:
                        short_segment = segment[:100] + "..."
                        retry_success, retry_result = self.synthesize_text_with_retry(
                            short_segment, ref_audio_path, ref_text_path
                        )
                        if retry_success:
                            segment_files.append((i, retry_result))
                            print(f"ğŸ”„ ç¬¬ {i + 1} æ®µé‡è¯•æˆåŠŸï¼ˆæˆªæ–­ç‰ˆï¼‰")

            if not segment_files:
                return False, "æ‰€æœ‰åˆ†æ®µåˆæˆå¤±è´¥"

            # æŒ‰ç´¢å¼•æ’åº
            segment_files.sort(key=lambda x: x[0])

            # ä¿®å¤ï¼šåªä¼ é€’éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨ï¼Œä¸ä¼ é€’ref_audio_path
            audio_files_to_merge = [s[1] for s in segment_files]

            # åˆå¹¶éŸ³é¢‘æ–‡ä»¶
            final_audio_path = self._merge_audio_segments(audio_files_to_merge)

            # å¦‚æœåˆå¹¶å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ›´ç®€å•çš„åˆå¹¶æ–¹å¼
            if not final_audio_path:
                # åˆ›å»ºæ–°çš„åˆå¹¶æ–‡ä»¶åï¼ˆä¸æ™®é€šåˆæˆæ ¼å¼ä¸€è‡´ï¼‰
                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                ref_audio_name = os.path.splitext(os.path.basename(ref_audio_path))[0]
                final_audio_path = os.path.join(
                    self.default_tts_config["output_path"],
                    f"{ref_audio_name}_merged_{timestamp}.wav"
                )

                # ç®€å•çš„éŸ³é¢‘åˆå¹¶ï¼ˆåªå¤åˆ¶ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼‰
                if audio_files_to_merge and os.path.exists(audio_files_to_merge[0]):
                    import shutil
                    shutil.copy2(audio_files_to_merge[0], final_audio_path)
                    print(f"âš ï¸  ä½¿ç”¨ç®€å•åˆå¹¶æ–¹å¼ï¼Œåªä¿ç•™ç¬¬ä¸€æ®µéŸ³é¢‘")

            if final_audio_path:
                # print(f"âœ… åˆ†æ®µåˆæˆå®Œæˆï¼Œåˆå¹¶ä¸º: {os.path.basename(final_audio_path)}")

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                for _, segment_file in segment_files:
                    try:
                        if os.path.exists(segment_file) and segment_file != final_audio_path:
                            os.remove(segment_file)
                    except:
                        pass

                return True, final_audio_path
            else:
                # å¦‚æœåˆå¹¶å¤±è´¥ï¼Œè‡³å°‘æ’­æ”¾ç¬¬ä¸€æ®µ
                first_audio = segment_files[0][1]
                print(f"âš ï¸  éŸ³é¢‘åˆå¹¶å¤±è´¥ï¼Œå°†æ’­æ”¾ç¬¬ä¸€æ®µéŸ³é¢‘")
                return True, first_audio

        except Exception as e:
            print(f"âŒ åˆ†æ®µåˆæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False, f"åˆ†æ®µåˆæˆå¤±è´¥: {str(e)}"

    def _split_text_by_numbered_sections(self, text: str) -> list[str]:
        """
        æŒ‰åºå·åˆ†æ®µæ–‡æœ¬ï¼ˆæ”¹è¿›ç‰ˆï¼‰

        Args:
            text: è¦åˆ†æ®µçš„æ–‡æœ¬

        Returns:
            åˆ†æ®µåçš„æ–‡æœ¬åˆ—è¡¨
        """
        segments = []

        # å¤šç§åºå·æ¨¡å¼ï¼ˆä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼‰
        patterns = [
            (r'### (\d+\.)', 3),  # Markdownä¸‰çº§æ ‡é¢˜
            (r'## (\d+\.)', 2),  # MarkdownäºŒçº§æ ‡é¢˜
            (r'(\d+\.\s)', 1),  # æ•°å­—åŠ ç‚¹ï¼ˆè‹±æ–‡ï¼‰
            (r'(\d+ã€\s)', 1),  # æ•°å­—åŠ é¡¿å·ï¼ˆä¸­æ–‡ï¼‰
            (r'\((\d+)\)\s', 1),  # æ‹¬å·æ•°å­—
            (r'ä¸€ã€', 1),  # ä¸­æ–‡åºå·
            (r'äºŒã€', 1),
            (r'ä¸‰ã€', 1),
            (r'å››ã€', 1),
            (r'äº”ã€', 1),
            (r'é¦–å…ˆ', 1),  # è¿æ¥è¯
            (r'å…¶æ¬¡', 1),
            (r'å†æ¬¡', 1),
            (r'æœ€å', 1),
        ]

        best_pattern = None
        best_matches = []

        # å¯»æ‰¾æœ€ä½³åˆ†æ®µæ¨¡å¼
        for pattern, priority in patterns:
            matches = list(re.finditer(pattern, text))
            if len(matches) >= 2:  # è‡³å°‘æœ‰2ä¸ªåŒ¹é…
                if not best_matches or (
                len(matches) > len(best_matches) and priority >= patterns[patterns.index((best_pattern, 0))][
                    1] if best_pattern else 0):
                    best_pattern = pattern
                    best_matches = matches

        # ä½¿ç”¨æœ€ä½³æ¨¡å¼åˆ†æ®µ
        if best_pattern and best_matches:
            # ä»ç¬¬ä¸€ä¸ªåˆ†æ®µç‚¹å¼€å§‹
            start_pos = 0
            last_end_pos = 0

            for i, match in enumerate(best_matches):
                if i == 0:
                    # ç¬¬ä¸€æ®µï¼šä»å¼€å¤´åˆ°ç¬¬ä¸€ä¸ªåˆ†æ®µç‚¹
                    segment = text[start_pos:match.start()].strip()
                    if segment and len(segment) > 10:  # ç¡®ä¿ä¸æ˜¯ç©ºæ®µ
                        segments.append(segment)
                    start_pos = match.start()
                    last_end_pos = match.start()
                    continue

                # ä¸­é—´æ®µï¼šä»å‰ä¸€ä¸ªåˆ†æ®µç‚¹åˆ°å½“å‰åˆ†æ®µç‚¹
                segment = text[last_end_pos:match.start()].strip()
                if segment and len(segment) > 10:
                    segments.append(segment)
                last_end_pos = match.start()

            # æœ€åä¸€æ®µï¼šä»æœ€åä¸€ä¸ªåˆ†æ®µç‚¹åˆ°ç»“å°¾
            last_segment = text[last_end_pos:].strip()
            if last_segment and len(last_segment) > 10:
                segments.append(last_segment)

            # æ£€æŸ¥åˆ†æ®µè´¨é‡
            if segments and len(segments) >= 2:
                avg_length = sum(len(s) for s in segments) / len(segments)
                if 50 <= avg_length <= self.max_text_length * 2:
                    return segments
                else:
                    segments = []

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„åºå·åˆ†æ®µï¼Œå°è¯•æŒ‰æ®µè½åˆ†æ®µ
        if not segments:
            # æŒ‰ç©ºè¡Œåˆ†æ®µ
            paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
            if len(paragraphs) >= 2:
                # åˆå¹¶è¿‡çŸ­çš„æ®µè½
                merged = []
                buffer = ""

                for para in paragraphs:
                    if len(buffer) + len(para) < self.max_text_length:
                        if buffer:
                            buffer += "\n\n" + para
                        else:
                            buffer = para
                    else:
                        if buffer:
                            merged.append(buffer)
                        buffer = para

                if buffer:
                    merged.append(buffer)

                if len(merged) >= 2:
                    return merged

        # æœ€åå°è¯•æŒ‰æ ‡ç‚¹åˆ†æ®µ
        if not segments:
            segments = self._split_text_by_punctuation(text)

        return segments

    def _split_text_by_punctuation(self, text: str) -> list[str]:
        """
        æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†æ®µ

        Args:
            text: è¦åˆ†æ®µçš„æ–‡æœ¬

        Returns:
            åˆ†æ®µåçš„æ–‡æœ¬åˆ—è¡¨
        """
        segments = []
        current_segment = ""

        # æ ‡ç‚¹ç¬¦å·åˆ—è¡¨
        punctuation_marks = ['ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼›', '.', '!', '?', ';']

        for char in text:
            current_segment += char

            # å¦‚æœé‡åˆ°æ ‡ç‚¹ï¼Œå¹¶ä¸”å½“å‰æ®µè¾¾åˆ°ä¸€å®šé•¿åº¦
            if char in punctuation_marks and len(current_segment) >= 50:
                segments.append(current_segment.strip())
                current_segment = ""

            # å¦‚æœå½“å‰æ®µè¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œå¼ºåˆ¶åˆ†æ®µ
            elif len(current_segment) >= self.max_text_length:
                # åœ¨æœ€åå‡ºç°çš„æ ‡ç‚¹å¤„åˆ†æ®µ
                last_punct = -1
                for punct in punctuation_marks:
                    pos = current_segment.rfind(punct)
                    if pos > last_punct:
                        last_punct = pos

                if last_punct > 0:
                    segments.append(current_segment[:last_punct + 1].strip())
                    current_segment = current_segment[last_punct + 1:]
                else:
                    # æ²¡æœ‰æ ‡ç‚¹ï¼ŒæŒ‰é•¿åº¦ç¡¬åˆ‡
                    segments.append(current_segment.strip())
                    current_segment = ""

        # æ·»åŠ æœ€åä¸€æ®µ
        if current_segment.strip():
            segments.append(current_segment.strip())

        # åˆå¹¶è¿‡çŸ­çš„æ®µè½
        merged_segments = []
        buffer = ""

        for segment in segments:
            if len(buffer) + len(segment) < self.max_text_length * 0.7:
                buffer += " " + segment if buffer else segment
            else:
                if buffer:
                    merged_segments.append(buffer)
                buffer = segment

        if buffer:
            merged_segments.append(buffer)

        print(f"ğŸ“ æŒ‰æ ‡ç‚¹åˆ†æ®µï¼Œåˆå¹¶å: {len(merged_segments)} æ®µ")
        return merged_segments

    def _synthesize_segment_thread(self, index: int, text: str, ref_audio_path: str,
                                   ref_text_path: str, results_queue: queue.Queue):
        """
        å•ä¸ªåˆ†æ®µåˆæˆçº¿ç¨‹

        Args:
            index: åˆ†æ®µç´¢å¼•
            text: åˆ†æ®µæ–‡æœ¬
            ref_audio_path: å‚è€ƒéŸ³é¢‘è·¯å¾„
            ref_text_path: å‚è€ƒæ–‡æœ¬è·¯å¾„
            results_queue: ç»“æœé˜Ÿåˆ—
        """
        try:
            print(f"ğŸµ å¼€å§‹åˆæˆç¬¬ {index + 1} æ®µï¼Œé•¿åº¦: {len(text)} å­—ç¬¦")

            # åˆæˆå½“å‰åˆ†æ®µ
            success, result = self.synthesize_text(
                text, ref_audio_path, ref_text_path, auto_play=False
            )

            if success:
                print(f"âœ… ç¬¬ {index + 1} æ®µåˆæˆæˆåŠŸ: {os.path.basename(result)}")
                results_queue.put((True, index, result))
            else:
                print(f"âŒ ç¬¬ {index + 1} æ®µåˆæˆå¤±è´¥: {result}")
                results_queue.put((False, index, f"åˆ†æ®µ{index + 1}å¤±è´¥"))

        except Exception as e:
            print(f"âŒ ç¬¬ {index + 1} æ®µåˆæˆå¼‚å¸¸: {e}")
            results_queue.put((False, index, f"åˆ†æ®µ{index + 1}å¼‚å¸¸"))

    def synthesize_text_with_retry(self, text: str, ref_audio_path: str, ref_text_path: str,
                                   max_retries: int = 2, retry_delay: float = 1.0) -> Tuple[bool, str]:
        """
        å¸¦é‡è¯•æœºåˆ¶çš„æ–‡æœ¬åˆæˆ

        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            ref_audio_path: å‚è€ƒéŸ³é¢‘è·¯å¾„
            ref_text_path: å‚è€ƒæ–‡æœ¬è·¯å¾„
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            retry_delay: é‡è¯•å»¶è¿Ÿ(ç§’)

        Returns:
            (success, result)
        """
        for attempt in range(max_retries + 1):
            try:
                # æ£€æŸ¥æ˜¯å¦æ­£åœ¨åˆæˆ
                with self.is_tts_synthesizing_lock:
                    if self.is_tts_synthesizing:
                        if attempt < max_retries:
                            print(f"ğŸ”„ ç¬¬{attempt + 1}æ¬¡é‡è¯•: TTSæ­£åœ¨åˆæˆä¸­ï¼Œç­‰å¾…{retry_delay}ç§’...")
                            time.sleep(retry_delay)
                            continue
                        else:
                            return False, "TTSæ­£å¿™ï¼Œè¯·ç¨åå†è¯•"

                    # è®¾ç½®åˆæˆæ ‡å¿—
                    self.is_tts_synthesizing = True

                # å°è¯•åˆæˆ
                success, result = self._synthesize_text_internal(text, ref_audio_path, ref_text_path)

                if success:
                    return True, result
                elif "åˆæˆä¸­" in result and attempt < max_retries:
                    print(f"ğŸ”„ ç¬¬{attempt + 1}æ¬¡é‡è¯•: {result}")
                    time.sleep(retry_delay)
                else:
                    return success, result

            except Exception as e:
                if attempt < max_retries:
                    print(f"ğŸ”„ ç¬¬{attempt + 1}æ¬¡é‡è¯•: å¼‚å¸¸ {e}")
                    time.sleep(retry_delay)
                else:
                    return False, f"åˆæˆå¼‚å¸¸: {str(e)}"
            finally:
                # ç¡®ä¿é”è¢«é‡Šæ”¾
                with self.is_tts_synthesizing_lock:
                    self.is_tts_synthesizing = False

        return False, "è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°"

    def _synthesize_text_internal(self, text: str, ref_audio_path: str, ref_text_path: str) -> tuple[bool, str]:
        """
        å†…éƒ¨åˆæˆæ–¹æ³• - å®é™…çš„æ–‡æœ¬åˆ°è¯­éŸ³åˆæˆé€»è¾‘

        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            ref_audio_path: å‚è€ƒéŸ³é¢‘è·¯å¾„
            ref_text_path: å‚è€ƒæ–‡æœ¬è·¯å¾„

        Returns:
            (success, éŸ³é¢‘æ–‡ä»¶è·¯å¾„æˆ–é”™è¯¯ä¿¡æ¯)
        """
        # æ£€æŸ¥æ¨¡å—æ˜¯å¦å·²åŠ è½½
        if not self.tts_modules_loaded:
            success, message = self.load_tts_modules()
            if not success:
                return False, message

        if not self.tts_available:
            return False, "TTSæ¨¡å—ä¸å¯ç”¨"

        # æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(ref_audio_path):
            return False, f"å‚è€ƒéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {ref_audio_path}"
        if not os.path.exists(ref_text_path):
            return False, f"å‚è€ƒæ–‡æœ¬æ–‡ä»¶ä¸å­˜åœ¨: {ref_text_path}"

        try:
            # è¯»å–å‚è€ƒæ–‡æœ¬ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
            ref_text_content = self._get_cached_text(ref_text_path)

            if not ref_text_content:
                return False, "å‚è€ƒæ–‡æœ¬å†…å®¹ä¸ºç©º"

            # æ£€æŸ¥å‡½æ•°æ˜¯å¦å¯ç”¨
            if 'get_tts_wav' not in self.tts_modules:
                return False, "TTSåˆæˆå‡½æ•°æœªåˆå§‹åŒ–"

            # æ¸…ç†æ–‡æœ¬
            cleaned_text = self._clean_text_for_tts(text)

            # æ£€æŸ¥æ¸…ç†åçš„æ–‡æœ¬è´¨é‡
            if not cleaned_text or len(cleaned_text) < 5:
                print(f"âš ï¸  æ¸…ç†åçš„æ–‡æœ¬è¿‡çŸ­ï¼ˆé•¿åº¦: {len(cleaned_text) if cleaned_text else 0}ï¼‰ï¼Œä½¿ç”¨é»˜è®¤æ–‡æœ¬")
                cleaned_text = "ä½ å¥½ï¼Œæˆ‘æ˜¯å°èŠ¸ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡"

            # æ£€æŸ¥ä¸­æ–‡å­—ç¬¦å æ¯”
            chinese_char_count = len([c for c in cleaned_text if '\u4e00' <= c <= '\u9fff'])
            if chinese_char_count < 2:
                print(f"âš ï¸  æ–‡æœ¬ä¸­æ–‡å­—ç¬¦è¿‡å°‘ï¼ˆ{chinese_char_count}ä¸ªï¼‰ï¼Œä½¿ç”¨é»˜è®¤æ–‡æœ¬")
                cleaned_text = "ä½ å¥½ï¼Œæˆ‘æ˜¯å°èŠ¸ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡"

            # ä½¿ç”¨æ“ä½œç³»ç»Ÿçº§åˆ«çš„è¾“å‡ºé‡å®šå‘
            if os.name == 'nt':  # Windows
                null_device = 'nul'
            else:  # Linux/Mac
                null_device = '/dev/null'

            # ä¿å­˜åŸå§‹çš„stdoutå’Œstderræ–‡ä»¶æè¿°ç¬¦
            original_stdout_fd = os.dup(1)
            original_stderr_fd = os.dup(2)

            # æ‰“å¼€ç©ºè®¾å¤‡
            null_fd = os.open(null_device, os.O_WRONLY)

            synthesis_result = None

            try:
                # å°†stdoutå’Œstderré‡å®šå‘åˆ°ç©ºè®¾å¤‡
                os.dup2(null_fd, 1)  # stdout
                os.dup2(null_fd, 2)  # stderr

                # ä¹Ÿé‡å®šå‘Pythonå±‚çš„sys.stdoutå’Œsys.stderr
                original_sys_stdout = sys.stdout
                original_sys_stderr = sys.stderr

                class NullWriter:
                    def write(self, s):
                        return len(s)

                    def flush(self):
                        pass

                null_writer = NullWriter()
                sys.stdout = null_writer
                sys.stderr = null_writer

                # è®¾ç½®ç¯å¢ƒå˜é‡ç¡®ä¿é™é»˜
                os.environ['TQDM_DISABLE'] = '1'
                os.environ['PROGRESS_BAR'] = '0'

                # æŠ‘åˆ¶æ—¥å¿—
                import logging
                logging.getLogger().setLevel(logging.CRITICAL)

                try:
                    # æ‰§è¡Œåˆæˆ
                    get_tts_wav = self.tts_modules['get_tts_wav']
                    i18n = self.tts_modules['i18n']

                    # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨é»˜è®¤å‚æ•°ï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
                    synthesis_result = get_tts_wav(
                        ref_wav_path=ref_audio_path,
                        prompt_text=ref_text_content,
                        prompt_language=i18n(self.default_tts_config["ref_language"]),
                        text=cleaned_text,
                        text_language=i18n(self.default_tts_config["target_language"]),
                        top_p=1.0,
                        temperature=1.0,
                        speed=1.0
                    )
                finally:
                    # æ¢å¤Pythonå±‚çš„è¾“å‡º
                    sys.stdout = original_sys_stdout
                    sys.stderr = original_sys_stderr
                    # æ¢å¤æ—¥å¿—çº§åˆ«
                    logging.getLogger().setLevel(logging.WARNING)

            finally:
                # æ¢å¤æ–‡ä»¶æè¿°ç¬¦
                os.dup2(original_stdout_fd, 1)
                os.dup2(original_stderr_fd, 2)
                # å…³é—­æ–‡ä»¶æè¿°ç¬¦
                os.close(original_stdout_fd)
                os.close(original_stderr_fd)
                os.close(null_fd)

            if synthesis_result:
                result_list = list(synthesis_result)
                if result_list:
                    sampling_rate, audio_data = result_list[-1]

                    # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
                    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

                    # ä½¿ç”¨å‚è€ƒéŸ³é¢‘çš„æ–‡ä»¶åï¼ˆå»æ‰åç¼€ï¼‰+ æ—¶é—´æˆ³
                    ref_audio_name = os.path.splitext(os.path.basename(ref_audio_path))[0]
                    output_wav = os.path.join(self.default_tts_config["output_path"], f"{ref_audio_name}_{timestamp}.wav")

                    # ç¡®ä¿ç›®å½•å­˜åœ¨
                    os.makedirs(os.path.dirname(output_wav), exist_ok=True)

                    # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
                    sf.write(output_wav, audio_data, sampling_rate)

                    # æ·»åŠ åˆ°åˆæˆæ–‡ä»¶åˆ—è¡¨
                    with self.tts_synthesized_files_lock:
                        self.tts_synthesized_files.append((output_wav, os.path.basename(output_wav)))

                    return True, output_wav

            return False, "åˆæˆå¤±è´¥ï¼šæ— éŸ³é¢‘æ•°æ®è¿”å›"

        except Exception as e:
            error_msg = f"åˆæˆå‡ºé”™ï¼š{str(e)}"
            print(f"âŒ TTSåˆæˆé”™è¯¯è¯¦æƒ…: {error_msg}")
            import traceback
            traceback.print_exc()
            return False, error_msg

    def _merge_audio_segments(self, audio_files: List[str]) -> Optional[str]:
        """
        åˆå¹¶å¤šä¸ªéŸ³é¢‘æ–‡ä»¶

        Args:
            audio_files: éŸ³é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨

        Returns:
            åˆå¹¶åçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        if not audio_files:
            return None

        if len(audio_files) == 1:
            return audio_files[0]  # åªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼Œä¸éœ€è¦åˆå¹¶

        try:
            import numpy as np
            import soundfile as sf

            # print(f"ğŸ”Š å¼€å§‹åˆå¹¶ {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶...")

            # è¯»å–æ‰€æœ‰éŸ³é¢‘æ•°æ®
            all_audio_data = []
            all_sample_rates = []

            for i, audio_file in enumerate(audio_files):
                if os.path.exists(audio_file):
                    data, samplerate = sf.read(audio_file)
                    all_audio_data.append(data)
                    all_sample_rates.append(samplerate)
                    # print(
                    # f"  - æ–‡ä»¶ {i + 1}: {os.path.basename(audio_file)}, é‡‡æ ·ç‡: {samplerate}, é•¿åº¦: {len(data) / samplerate:.2f}ç§’")
                else:
                    print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")

            if not all_audio_data:
                return None

            # æ£€æŸ¥é‡‡æ ·ç‡æ˜¯å¦ä¸€è‡´
            if len(set(all_sample_rates)) > 1:
                print(f"âš ï¸  é‡‡æ ·ç‡ä¸ä¸€è‡´ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ–‡ä»¶çš„é‡‡æ ·ç‡: {all_sample_rates[0]}")

            target_samplerate = all_sample_rates[0]

            # åˆå¹¶éŸ³é¢‘æ•°æ®
            # å¯¹äºç«‹ä½“å£°éŸ³é¢‘ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
            if len(all_audio_data[0].shape) == 2:  # ç«‹ä½“å£°
                merged_data = np.vstack(all_audio_data)
            else:  # å•å£°é“
                merged_data = np.concatenate(all_audio_data)

            # ä¿å­˜åˆå¹¶åçš„éŸ³é¢‘ - ä½¿ç”¨ä¸æ™®é€šåˆæˆä¸€è‡´çš„æ ¼å¼
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

            # ä»ç¬¬ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶åä¸­æå–å‚è€ƒéŸ³é¢‘åç§°
            first_audio_file = audio_files[0]
            first_audio_name = os.path.basename(first_audio_file)

            # æå–å‚è€ƒéŸ³é¢‘åç§°ï¼ˆå»æ‰æ—¶é—´æˆ³éƒ¨åˆ†ï¼‰
            # æ ¼å¼å¦‚: "ref_audio_name_20250119_123456.wav"
            import re
            match = re.match(r'(.+)_\d{8}_\d{6}', first_audio_name)
            if match:
                ref_audio_base = match.group(1)
            else:
                # å¦‚æœæ— æ³•è§£æï¼Œä½¿ç”¨é»˜è®¤åç§°
                ref_audio_base = "tts_merged"

            output_wav = os.path.join(
                self.default_tts_config["output_path"],
                f"{ref_audio_base}_merged_{timestamp}.wav"
            )

            sf.write(output_wav, merged_data, target_samplerate)

            return output_wav

        except ImportError as e:
            print(f"âŒ éŸ³é¢‘åˆå¹¶éœ€è¦soundfileå’Œnumpyåº“: {e}")
            print("ğŸ’¡ è¯·å®‰è£…: pip install soundfile numpy")
            # è¿”å›ç¬¬ä¸€ä¸ªæ–‡ä»¶ä½œä¸ºå¤‡é€‰
            return audio_files[0]

        except Exception as e:
            print(f"âŒ éŸ³é¢‘åˆå¹¶å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            # è¿”å›ç¬¬ä¸€ä¸ªæ–‡ä»¶ä½œä¸ºå¤‡é€‰
            return audio_files[0]

    def should_use_segmented_synthesis(self, text: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨åˆ†æ®µåˆæˆ

        Args:
            text: è¦åˆ¤æ–­çš„æ–‡æœ¬

        Returns:
            Trueå¦‚æœåº”è¯¥ä½¿ç”¨åˆ†æ®µåˆæˆ
        """
        if not text:
            return False

        cleaned_text = self._clean_text_for_tts(text)

        # æ–‡æœ¬é•¿åº¦è¶…è¿‡é˜ˆå€¼
        if len(cleaned_text) > self.max_text_length * 1.5:  # è¶…è¿‡750å­—ç¬¦
            return True

        # åŒ…å«å¤šä¸ªåºå·æ®µè½
        numbered_patterns = [r'\d+\.\s', r'\d+ã€\s', r'\(\d+\)\s']
        for pattern in numbered_patterns:
            if len(re.findall(pattern, cleaned_text)) >= 2:
                return True

        return False

    def speak_text_intelligently(self, text: str) -> bool:
        """
        æ™ºèƒ½è¯­éŸ³åˆæˆï¼ˆè‡ªåŠ¨åˆ¤æ–­æ˜¯å¦åˆ†æ®µï¼‰

        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬

        Returns:
            Trueå¦‚æœåˆæˆæˆåŠŸ
        """
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å‚è€ƒéŸ³é¢‘å’Œæ–‡æœ¬
            ref_audio = self.get_current_model("audio")
            ref_text = self.get_current_model("text")

            if not ref_audio or not ref_text:
                print("âš ï¸  æ— æ³•è¯­éŸ³æ’­æŠ¥ï¼šæœªé€‰æ‹©å‚è€ƒéŸ³é¢‘æˆ–æ–‡æœ¬")
                return False

            # æ£€æŸ¥TTSæ˜¯å¦å¯ç”¨
            if not self.tts_enabled:
                print("âš ï¸  TTSåŠŸèƒ½æœªå¯ç”¨")
                return False

            # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨åˆ†æ®µåˆæˆ
            if self.should_use_segmented_synthesis(text):
                print(f"ğŸ“ æ–‡æœ¬è¾ƒé•¿({len(text)}å­—ç¬¦)ï¼Œä½¿ç”¨åˆ†æ®µä¸²è¡Œåˆæˆ...")

                def async_synthesize():
                    try:
                        # ä½¿ç”¨ä¸²è¡Œåˆæˆ
                        success, audio_path = self.synthesize_long_text_serial(
                            text, ref_audio, ref_text
                        )

                        if success and audio_path:
                            # æ’­æ”¾åˆå¹¶åçš„éŸ³é¢‘
                            self.play_audio_file(audio_path)
                        else:
                            logger.error(f"åˆ†æ®µè¯­éŸ³åˆæˆå¤±è´¥: {audio_path}")

                            # åˆ†æ®µåˆæˆå¤±è´¥ï¼Œå°è¯•æ™®é€šåˆæˆ
                            print("ğŸ”„ åˆ†æ®µå¤±è´¥ï¼Œå°è¯•æ™®é€šåˆæˆ...")
                            # ä½¿ç”¨æ¸…ç†åçš„æ–‡æœ¬ï¼Œç¡®ä¿è´¨é‡
                            fallback_text = self._clean_text_for_tts(text[:500])
                            if len(fallback_text) < 5 or len([c for c in fallback_text if '\u4e00' <= c <= '\u9fff']) < 2:
                                fallback_text = "ä½ å¥½ï¼Œæˆ‘æ˜¯å°èŠ¸ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡"
                            fallback_success, _ = self.synthesize_text(
                                fallback_text, ref_audio, ref_text, auto_play=True
                            )
                            if fallback_success:
                                print("\n")
                    except Exception as e:
                        print(f"âŒ åˆ†æ®µè¯­éŸ³åˆæˆå¼‚å¸¸: {e}")

                # å¼‚æ­¥æ‰§è¡Œåˆ†æ®µåˆæˆ
                self.executor.submit(async_synthesize)
                return True

            else:
                def async_synthesize():
                    try:
                        success, _ = self.synthesize_text(
                            text, ref_audio, ref_text, auto_play=True
                        )
                        if success:
                            print("\n")
                    except Exception as e:
                        print(f"âŒ è¯­éŸ³åˆæˆå¼‚å¸¸: {e}\n")

                # å¼‚æ­¥æ‰§è¡Œæ™®é€šåˆæˆ
                threading.Thread(target=async_synthesize, daemon=True).start()
                return True

        except Exception as e:
            print(f"âŒ æ™ºèƒ½è¯­éŸ³åˆæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def _init_audio_player(self):
        """åˆå§‹åŒ–éŸ³é¢‘æ’­æ”¾å™¨"""
        try:
            self.audio_player = pyaudio.PyAudio()
            print("âœ… éŸ³é¢‘æ’­æ”¾å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–éŸ³é¢‘æ’­æ”¾å¤±è´¥: {e}")
            self.audio_player = None

    def init_tts_files_database(self) -> bool:
        """åˆå§‹åŒ–TTSæ–‡ä»¶æ•°æ®åº“"""
        print("ğŸ” åˆå§‹åŒ–TTSæ–‡ä»¶æ•°æ®åº“...")

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        for dir_path in [
            self.default_tts_config["gpt_model_dir"],
            self.default_tts_config["sovits_model_dir"],
            self.default_tts_config["ref_audio_root"],
            self.default_tts_config["output_path"]
        ]:
            os.makedirs(dir_path, exist_ok=True)
            print(f"ğŸ“ ç¡®ä¿ç›®å½•å­˜åœ¨: {dir_path}")

        # æ‰«æGPTæ¨¡å‹
        self.tts_files_database["gpt"] = {}
        if os.path.exists(self.default_tts_config["gpt_model_dir"]):
            for root, _, files in os.walk(self.default_tts_config["gpt_model_dir"]):
                for file in files:
                    if file.endswith('.ckpt'):
                        abs_path = os.path.normpath(os.path.join(root, file))
                        self.tts_files_database["gpt"][file] = abs_path
        else:
            print(f"âš ï¸  GPTæ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {self.default_tts_config['gpt_model_dir']}")

        # æ‰«æSoVITSæ¨¡å‹
        self.tts_files_database["sovits"] = {}
        if os.path.exists(self.default_tts_config["sovits_model_dir"]):
            for root, _, files in os.walk(self.default_tts_config["sovits_model_dir"]):
                for file in files:
                    if file.endswith('.pth'):
                        abs_path = os.path.normpath(os.path.join(root, file))
                        self.tts_files_database["sovits"][file] = abs_path
        else:
            print(f"âš ï¸  SoVITSæ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {self.default_tts_config['sovits_model_dir']}")

        # æ‰«æå‚è€ƒéŸ³é¢‘
        self.tts_files_database["audio"] = {}
        if os.path.exists(self.default_tts_config["ref_audio_root"]):
            for root, _, files in os.walk(self.default_tts_config["ref_audio_root"]):
                for file in files:
                    if file.endswith(('.wav', '.mp3', '.flac')):
                        abs_path = os.path.normpath(os.path.join(root, file))
                        self.tts_files_database["audio"][file] = abs_path
        else:
            print(f"âš ï¸  å‚è€ƒéŸ³é¢‘ç›®å½•ä¸å­˜åœ¨: {self.default_tts_config['ref_audio_root']}")

        # æ‰«æå‚è€ƒæ–‡æœ¬
        self.tts_files_database["text"] = {}
        if os.path.exists(self.default_tts_config["ref_text_root"]):
            for root, _, files in os.walk(self.default_tts_config["ref_text_root"]):
                for file in files:
                    if file.endswith('.txt'):
                        abs_path = os.path.normpath(os.path.join(root, file))
                        self.tts_files_database["text"][file] = abs_path
        else:
            print(f"âš ï¸  å‚è€ƒæ–‡æœ¬ç›®å½•ä¸å­˜åœ¨: {self.default_tts_config['ref_text_root']}")

        print(f"âœ… æ–‡ä»¶æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ:")
        print(f"   - GPTæ¨¡å‹: {len(self.tts_files_database['gpt'])} ä¸ª")
        print(f"   - SoVITSæ¨¡å‹: {len(self.tts_files_database['sovits'])} ä¸ª")
        print(f"   - å‚è€ƒéŸ³é¢‘: {len(self.tts_files_database['audio'])} ä¸ª")
        print(f"   - å‚è€ƒæ–‡æœ¬: {len(self.tts_files_database['text'])} ä¸ª")

        return True

    def load_tts_modules(self) -> Tuple[bool, str]:
        """åŠ è½½TTSæ¨¡å—"""
        if self.tts_modules_loaded:
            return True, "æ¨¡å—å·²åŠ è½½"

        try:
            print("ğŸ“¦ æ­£åœ¨åŠ è½½TTSæ¨¡å—...")

            # è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œå‡å°‘å†—ä½™è¾“å‡º
            os.environ["TRANSFORMERS_OFFLINE"] = "1"
            os.environ["HF_HUB_OFFLINE"] = "1"
            os.environ["TQDM_DISABLE"] = "1"  # ç¦ç”¨tqdmè¿›åº¦æ¡
            os.environ["TOKENIZERS_PARALLELISM"] = "false"

            # æŠ‘åˆ¶transformersçš„æ—¥å¿—
            import logging
            logging.getLogger("transformers").setLevel(logging.ERROR)
            logging.getLogger("torch").setLevel(logging.WARNING)

            # è®¾ç½®æ¨¡å‹è·¯å¾„
            if os.path.exists(self.bert_model_path):
                os.environ["bert_path"] = self.bert_model_path
                print(f"âœ… BERTæ¨¡å‹è·¯å¾„å·²è®¾ç½®")

            if os.path.exists(self.hubert_model_path):
                os.environ["cnhubert_base_path"] = self.hubert_model_path
                print(f"âœ… HuBERTæ¨¡å‹è·¯å¾„å·²è®¾ç½®")

            # å…³é”®ä¿®å¤ï¼šè®¾ç½®é»˜è®¤çš„GPTå’ŒSoVITSæ¨¡å‹è·¯å¾„
            if self.tts_files_database["gpt"]:
                first_gpt = list(self.tts_files_database["gpt"].values())[0]
                os.environ["gpt_path"] = first_gpt
                print(f"ğŸ“Œ é»˜è®¤GPTæ¨¡å‹: {os.path.basename(first_gpt)}")

            if self.tts_files_database["sovits"]:
                first_sovits = list(self.tts_files_database["sovits"].values())[0]
                os.environ["sovits_path"] = first_sovits
                print(f"ğŸ“Œ é»˜è®¤SoVITSæ¨¡å‹: {os.path.basename(first_sovits)}")

            # è®¾ç½®å…¶ä»–å¿…è¦ç¯å¢ƒå˜é‡
            os.environ["version"] = "v2"
            os.environ["is_half"] = "True" if torch.cuda.is_available() else "False"
            os.environ["language"] = "Auto"
            os.environ["infer_ttswebui"] = "9872"
            os.environ["is_share"] = "False"

            # ä¸´æ—¶é‡å®šå‘è¾“å‡ºï¼Œé¿å…æ¨¡å—å¯¼å…¥æ—¶çš„å†—ä½™ä¿¡æ¯
            import io
            import contextlib

            # åˆ›å»ºç©ºè®¾å¤‡
            class NullIO(io.StringIO):
                def write(self, text):
                    # åªä¿ç•™å…³é”®é”™è¯¯ä¿¡æ¯
                    if "error" in text.lower() or "exception" in text.lower():
                        return super().write(text)
                    return len(text)

            # å¯¼å…¥TTSæ¨¡å—æ—¶é‡å®šå‘è¾“å‡º
            with contextlib.redirect_stdout(NullIO()), contextlib.redirect_stderr(NullIO()):
                try:
                    from tools.i18n.i18n import I18nAuto
                    from GPT_SoVITS.inference_webui import change_gpt_weights, change_sovits_weights, \
                        get_tts_wav as real_get_tts_wav

                    # ä¿å­˜åˆ°æ¨¡å—å­—å…¸
                    self.tts_modules['I18nAuto'] = I18nAuto
                    self.tts_modules['change_gpt_weights'] = change_gpt_weights
                    self.tts_modules['change_sovits_weights'] = change_sovits_weights
                    self.tts_modules['get_tts_wav'] = real_get_tts_wav
                    self.tts_modules['i18n'] = I18nAuto()

                except ImportError as e:
                    print(f"âŒ TTSæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
                    self.tts_available = False
                    return False, f"æ¨¡å—å¯¼å…¥å¤±è´¥ï¼š{str(e)}"

            self.tts_modules_loaded = True
            self.tts_available = True
            print("âœ… TTSæ¨¡å—åŠ è½½æˆåŠŸ")

            return True, "æ¨¡å—åŠ è½½æˆåŠŸ"
        except Exception as e:
            print(f"âŒ TTSæ¨¡å—åŠ è½½å¤±è´¥: {e}")
            self.tts_available = False
            return False, f"æ¨¡å—åŠ è½½å¤±è´¥ï¼š{str(e)}"

    def synthesize_text(self, text: str, ref_audio_path: str, ref_text_path: str,
                        auto_play: bool = True) -> Tuple[bool, str]:
        """åˆæˆæ–‡æœ¬ä¸ºè¯­éŸ³"""
        with self.is_tts_synthesizing_lock:
            if self.is_tts_synthesizing:
                return False, "æ­£åœ¨åˆæˆä¸­ï¼Œè¯·ç¨å€™"
            self.is_tts_synthesizing = True

        # æ£€æŸ¥æ¨¡å—æ˜¯å¦å·²åŠ è½½
        if not self.tts_modules_loaded:
            success, message = self.load_tts_modules()
            if not success:
                with self.is_tts_synthesizing_lock:
                    self.is_tts_synthesizing = False
                return False, message

        if not self.tts_available:
            with self.is_tts_synthesizing_lock:
                self.is_tts_synthesizing = False
            return False, "TTSæ¨¡å—ä¸å¯ç”¨"

        try:
            # è¯»å–å‚è€ƒæ–‡æœ¬ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
            ref_text_content = self._get_cached_text(ref_text_path)

            # æ£€æŸ¥å‡½æ•°æ˜¯å¦å¯ç”¨
            if 'get_tts_wav' not in self.tts_modules:
                with self.is_tts_synthesizing_lock:
                    self.is_tts_synthesizing = False
                return False, "TTSåˆæˆå‡½æ•°æœªåˆå§‹åŒ–"

            # æ¸…ç†æ–‡æœ¬
            cleaned_text = self._clean_text_for_tts(text)

            # ä½¿ç”¨æ“ä½œç³»ç»Ÿçº§åˆ«çš„è¾“å‡ºé‡å®šå‘
            if os.name == 'nt':  # Windows
                null_device = 'nul'
            else:  # Linux/Mac
                null_device = '/dev/null'

            # ä¿å­˜åŸå§‹çš„stdoutå’Œstderræ–‡ä»¶æè¿°ç¬¦
            original_stdout_fd = os.dup(1)
            original_stderr_fd = os.dup(2)

            # æ‰“å¼€ç©ºè®¾å¤‡
            null_fd = os.open(null_device, os.O_WRONLY)

            try:
                # å°†stdoutå’Œstderré‡å®šå‘åˆ°ç©ºè®¾å¤‡
                os.dup2(null_fd, 1)  # stdout
                os.dup2(null_fd, 2)  # stderr

                # ä¹Ÿé‡å®šå‘Pythonå±‚çš„sys.stdoutå’Œsys.stderr
                original_sys_stdout = sys.stdout
                original_sys_stderr = sys.stderr

                class NullWriter:
                    def write(self, s):
                        return len(s)

                    def flush(self):
                        pass

                null_writer = NullWriter()
                sys.stdout = null_writer
                sys.stderr = null_writer

                # è®¾ç½®ç¯å¢ƒå˜é‡ç¡®ä¿é™é»˜
                os.environ['TQDM_DISABLE'] = '1'
                os.environ['PROGRESS_BAR'] = '0'

                # æŠ‘åˆ¶æ—¥å¿—
                import logging
                logging.getLogger().setLevel(logging.CRITICAL)

                try:
                    # æ‰§è¡Œåˆæˆ
                    get_tts_wav = self.tts_modules['get_tts_wav']
                    i18n = self.tts_modules['i18n']

                    synthesis_result = get_tts_wav(
                        ref_wav_path=ref_audio_path,
                        prompt_text=ref_text_content,
                        prompt_language=i18n(self.default_tts_config["ref_language"]),
                        text=cleaned_text,
                        text_language=i18n(self.default_tts_config["target_language"]),
                        top_p=1.0,
                        temperature=1.0,
                        speed=1.0
                    )
                finally:
                    # æ¢å¤Pythonå±‚çš„è¾“å‡º
                    sys.stdout = original_sys_stdout
                    sys.stderr = original_sys_stderr
                    # æ¢å¤æ—¥å¿—çº§åˆ«
                    logging.getLogger().setLevel(logging.WARNING)

            finally:
                # æ¢å¤æ–‡ä»¶æè¿°ç¬¦
                os.dup2(original_stdout_fd, 1)
                os.dup2(original_stderr_fd, 2)
                # å…³é—­æ–‡ä»¶æè¿°ç¬¦
                os.close(original_stdout_fd)
                os.close(original_stderr_fd)
                os.close(null_fd)

            if synthesis_result:
                result_list = list(synthesis_result)
                if result_list:
                    sampling_rate, audio_data = result_list[-1]

                    # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
                    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

                    # ä½¿ç”¨å‚è€ƒéŸ³é¢‘çš„æ–‡ä»¶åï¼ˆå»æ‰åç¼€ï¼‰+ æ—¶é—´æˆ³
                    ref_audio_name = os.path.splitext(os.path.basename(ref_audio_path))[0]
                    output_wav = os.path.join(self.default_tts_config["output_path"], f"{ref_audio_name}_{timestamp}.wav")

                    sf.write(output_wav, audio_data, sampling_rate)

                    # æ·»åŠ åˆ°åˆæˆæ–‡ä»¶åˆ—è¡¨
                    with self.tts_synthesized_files_lock:
                        self.tts_synthesized_files.append((output_wav, os.path.basename(output_wav)))

                        # è‡ªåŠ¨æ’­æ”¾
                        if auto_play:
                            def play_thread_func():
                                self.play_audio_file(output_wav)

                            self.executor.submit(play_thread_func)

                    with self.is_tts_synthesizing_lock:
                        self.is_tts_synthesizing = False
                    return True, output_wav

            with self.is_tts_synthesizing_lock:
                self.is_tts_synthesizing = False
            return False, "åˆæˆå¤±è´¥ï¼šæ— éŸ³é¢‘æ•°æ®è¿”å›"
        except Exception as e:
            with self.is_tts_synthesizing_lock:
                self.is_tts_synthesizing = False
            return False, f"åˆæˆå‡ºé”™ï¼š{str(e)}"

    def _clean_text_for_tts(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ï¼Œä½†ä¸ä¸¢å¤±å¼€å¤´éƒ¨åˆ†"""
        if not text:
            return "ä½ å¥½ï¼Œæˆ‘æ˜¯å°èŠ¸ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡"

        # ä¿å­˜åŸå§‹æ–‡æœ¬ä»¥ä¾¿åç»­å¤„ç†
        original_text = text

        # 1. ç§»é™¤ä»£ç å—æ ‡è®°
        text = re.sub(r'```[a-zA-Z]*\n?', '', text)
        text = re.sub(r'```', '', text)

        # 2. ç§»é™¤URLå’Œç‰¹æ®Šæ ‡è®°ï¼Œä½†ä¿ç•™ä¸­æ–‡æ ‡ç‚¹
        text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)
        text = re.sub(r'\[.*?\]', '', text)  # ç§»é™¤æ–¹æ‹¬å·å†…å®¹

        # 3. ä¿ç•™ä¸­æ–‡æ ‡ç‚¹ï¼šï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š"'
        text = re.sub(r'[^\w\u4e00-\u9fff\s\.,ï¼Œã€‚!ï¼?ï¼Ÿ:ï¼š;ï¼›ã€\'\"\(\)ï¼ˆï¼‰ã€Šã€‹ã€ã€‘\-]', '', text)

        # 4. ç§»é™¤å¤šä½™ç©ºæ ¼ï¼Œä½†ä¿ç•™ä¸€ä¸ªç©ºæ ¼
        text = ' '.join(text.split())

        # 5. æ£€æŸ¥æ¸…ç†åçš„æ–‡æœ¬é•¿åº¦
        cleaned_text = text.strip()

        # æ£€æŸ¥æ˜¯å¦ä¸»è¦æ˜¯è‹±æ–‡æˆ–ç‰¹æ®Šå­—ç¬¦
        chinese_char_count = len([c for c in cleaned_text if '\u4e00' <= c <= '\u9fff'])
        total_char_count = len(cleaned_text)

        # å¦‚æœä¸­æ–‡å­—ç¬¦å æ¯”å¤ªä½æˆ–æ–‡æœ¬å¤ªçŸ­ï¼Œä½¿ç”¨å…œåº•æ–‡æœ¬
        if total_char_count == 0 or (total_char_count > 0 and chinese_char_count / total_char_count < 0.3) or len(cleaned_text) < 3:
            print(f"âš ï¸  æ¸…ç†åçš„æ–‡æœ¬è´¨é‡ä¸ä½³ï¼ˆä¸­æ–‡å­—ç¬¦å æ¯”: {chinese_char_count}/{total_char_count}ï¼‰ï¼Œä½¿ç”¨å…œåº•æ–‡æœ¬")
            # ä½¿ç”¨æ›´é•¿çš„å…œåº•æ–‡æœ¬ï¼Œç¡®ä¿GPT-SoVITSèƒ½æ­£å¸¸å¤„ç†
            return "ä½ å¥½ï¼Œæˆ‘æ˜¯å°èŠ¸ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡"

        return cleaned_text

    def play_audio_file(self, audio_path: str):
        """æ’­æ”¾æŒ‡å®šçš„éŸ³é¢‘æ–‡ä»¶"""
        if not self.audio_player:
            print("âŒ éŸ³é¢‘æ’­æ”¾å™¨æœªåˆå§‹åŒ–")
            return

        with self.is_playing_audio_lock:
            if self.is_playing_audio:
                print("âš ï¸ å·²æœ‰éŸ³é¢‘æ­£åœ¨æ’­æ”¾ï¼Œè·³è¿‡æœ¬æ¬¡æ’­æ”¾è¯·æ±‚")
                return
            self.is_playing_audio = True

        if not os.path.exists(audio_path):
            print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼š{audio_path}")
            with self.is_playing_audio_lock:
                self.is_playing_audio = False
            return

        try:
            # æ‰“å¼€éŸ³é¢‘æ–‡ä»¶
            wf = wave.open(audio_path, 'rb')

            # åˆ›å»ºéŸ³é¢‘æµ
            stream = self.audio_player.open(
                format=self.audio_player.get_format_from_width(wf.getsampwidth()),
                channels=wf.getnchannels(),
                rate=wf.getframerate(),
                output=True
            )

            # åˆ†å—æ’­æ”¾éŸ³é¢‘ï¼ˆæ£€æŸ¥æ’­æ”¾çŠ¶æ€ï¼‰
            chunk = 1024
            data = wf.readframes(chunk)

            while data:
                with self.is_playing_audio_lock:
                    if not self.is_playing_audio:
                        break
                stream.write(data)
                data = wf.readframes(chunk)

            # æ¸…ç†èµ„æº
            stream.stop_stream()
            stream.close()
            wf.close()

        except Exception as e:
            print(f"âŒ æ’­æ”¾å¤±è´¥ï¼š{e}")
            traceback.print_exc()
        finally:
            # é‡Šæ”¾æ’­æ”¾é”
            with self.is_playing_audio_lock:
                self.is_playing_audio = False

    def stop_current_audio_playback(self) -> bool:
        """åœæ­¢å½“å‰æ­£åœ¨æ’­æ”¾çš„éŸ³é¢‘"""
        with self.is_playing_audio_lock:
            if self.is_playing_audio:
                self.is_playing_audio = False
                print("â¹ï¸ æ­£åœ¨åœæ­¢éŸ³é¢‘æ’­æ”¾...")
                return True
            else:
                return False

    def load_synthesized_files(self) -> List[Tuple[str, str]]:
        """åŠ è½½å·²åˆæˆéŸ³é¢‘æ–‡ä»¶"""
        with self.tts_synthesized_files_lock:
            self.tts_synthesized_files = []
            output_dir = self.default_tts_config["output_path"]
            if os.path.exists(output_dir):
                wav_files = [f for f in os.listdir(output_dir) if f.endswith('.wav')]
                for wav_file in sorted(wav_files, reverse=True):
                    abs_path = os.path.join(output_dir, wav_file)
                    self.tts_synthesized_files.append((abs_path, wav_file))
        return self.tts_synthesized_files

    def set_current_model(self, model_type: str, filename: str) -> bool:
        """è®¾ç½®å½“å‰é€‰ä¸­çš„æ¨¡å‹"""
        with self.current_models_lock:
            if model_type == "gpt":
                if filename in self.tts_files_database["gpt"]:
                    self.current_gpt_model = self.tts_files_database["gpt"][filename]
                    return True
            elif model_type == "sovits":
                if filename in self.tts_files_database["sovits"]:
                    self.current_sovits_model = self.tts_files_database["sovits"][filename]
                    return True
            elif model_type == "audio":
                if filename in self.tts_files_database["audio"]:
                    self.current_ref_audio = self.tts_files_database["audio"][filename]
                    return True
            elif model_type == "text":
                if filename in self.tts_files_database["text"]:
                    self.current_ref_text = self.tts_files_database["text"][filename]
                    return True
        return False

    def get_current_model(self, model_type: str) -> Optional[str]:
        """è·å–å½“å‰é€‰ä¸­çš„æ¨¡å‹"""
        with self.current_models_lock:
            if model_type == "gpt":
                return self.current_gpt_model
            elif model_type == "sovits":
                return self.current_sovits_model
            elif model_type == "audio":
                return self.current_ref_audio
            elif model_type == "text":
                return self.current_ref_text
        return None

    def get_model_filename(self, model_type: str) -> str:
        """è·å–å½“å‰é€‰ä¸­æ¨¡å‹çš„æ–‡ä»¶å"""
        model_path = self.get_current_model(model_type)
        if model_path:
            return os.path.basename(model_path)
        return "æœªé€‰æ‹©"

    def cleanup(self):
        """æ¸…ç†TTSèµ„æº"""
        print("ğŸ§¹ æ¸…ç†TTSèµ„æº...")

        # åœæ­¢éŸ³é¢‘æ’­æ”¾
        self.stop_current_audio_playback()

        # æ¸…ç†éŸ³é¢‘æ’­æ”¾å™¨
        if self.audio_player:
            try:
                self.audio_player.terminate()
            except:
                pass




class TaskManager:
    """ä»»åŠ¡ç®¡ç†å™¨ - è´Ÿè´£æ‰€æœ‰åå°ä»»åŠ¡çš„è°ƒåº¦å’Œæ‰§è¡Œ"""

    def __init__(self, project_root: str, scrcpy_path: str):
        self.project_root = project_root
        self.scrcpy_path = scrcpy_path

        # åˆå§‹åŒ–å·¥å…·å’Œæ¨¡å—
        self.utils = Utils()
        self.utils.enable_windows_color()

        # åˆ›å»ºæ¨¡å—å®ä¾‹
        self.connection_manager = ConnectionManager()
        self.file_manager = FileManager()

        # åˆå§‹åŒ–æ™ºè°±AIå®¢æˆ·ç«¯
        try:
            self.zhipu_client = ZhipuAI(api_key=ZHIPU_API_KEY)
            self.task_recognizer = TaskRecognizer(self.zhipu_client)
            self.agent_executor = AgentExecutor()
            print("âœ… å·²åˆå§‹åŒ–çœŸå®æ¨¡å—")
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å®¢æˆ·ç«¯å¤±è´¥: {e}")
            raise

        # åˆå§‹åŒ–TTSç®¡ç†å™¨
        self.tts_manager = TTSManager(project_root)

        # åˆå§‹åŒ–TTSæ–‡ä»¶æ•°æ®åº“
        try:
            self.tts_manager.init_tts_files_database()
        except Exception as e:
            print(f"âš ï¸  TTSæ–‡ä»¶æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")

        # é»˜è®¤TTSå…³é—­
        self.tts_manager.tts_enabled = False

        # çŠ¶æ€å˜é‡
        self.device_id = None
        self.config = {}
        self.is_connected = False
        self.task_args = None

        # åˆå§‹åŒ–æ–‡ä»¶ç³»ç»Ÿ
        self.file_manager.init_file_system()

        # åˆå§‹åŒ–å‘½ä»¤è¡Œå‚æ•°
        self._init_args()

        # è¿‡æ»¤å†—ä½™è­¦å‘Š
        warnings.filterwarnings('ignore')

    def _init_args(self):
        """åˆå§‹åŒ–å‘½ä»¤è¡Œå‚æ•°"""

        class Args:
            def __init__(self):
                self.base_url = "https://open.bigmodel.cn/api/paas/v4"
                self.model = "autoglm-phone"
                self.apikey = ZHIPU_API_KEY
                self.max_steps = 100
                self.device_id = None
                self.usb = False
                self.wireless = False
                self.ip = None
                self.port = "5555"
                self.setup = False
                self.quiet = False
                self.lang = "cn"
                self.task = None

        self.task_args = Args()

    def set_device_type(self, device_type: str):
        """è®¾ç½®è®¾å¤‡ç±»å‹"""
        self.connection_manager.set_device_type(device_type)
        print(f"ğŸ“± TaskManagerè®¾å¤‡ç±»å‹å·²åˆ‡æ¢ä¸º: {device_type}")

    # ========== è¿æ¥ç®¡ç†æ–¹æ³• ==========

    def check_initial_connection(self):
        """æ£€æŸ¥åˆå§‹è¿æ¥"""
        self.config = self.connection_manager.load_connection_config()

        if self.config.get("connection_type") == "usb" and self.config.get("usb_device_id"):
            self.try_connect()
        elif self.config.get("connection_type") == "wireless" and self.config.get("wireless_ip"):
            self.try_connect()

    def try_connect(self):
        """å°è¯•è¿æ¥è®¾å¤‡"""
        success, device_id, message = self.connection_manager.connect_to_device(self.config)

        if success:
            self.is_connected = True
            self.device_id = device_id
            self.task_args.device_id = device_id
            print(f"âœ… {message}")
        else:
            print(f"âŒ è¿æ¥å¤±è´¥: {message}")

    def connect_device(self, config: Dict[str, Any]) -> Tuple[bool, Optional[str], str]:
        """è¿æ¥è®¾å¤‡"""
        self.config = config
        self.connection_manager.save_connection_config(config)

        success, device_id, message = self.connection_manager.connect_to_device(config)

        if success:
            self.is_connected = True
            self.device_id = device_id
            self.task_args.device_id = device_id

        return success, device_id, message

    def setup_connection(self):
        """è®¾ç½®è¿æ¥"""
        config = self.connection_manager.interactive_setup_connection()
        success, device_id, message = self.connection_manager.connect_to_device(config)

        if success:
            self.is_connected = True
            self.device_id = device_id
            self.task_args.device_id = device_id
            print(f"âœ… é‡æ–°è¿æ¥æˆåŠŸ: {message}")
        else:
            print(f"âŒ é‡æ–°è¿æ¥å¤±è´¥: {message}")

    def detect_devices(self) -> List[str]:
        """æ£€æµ‹å¯ç”¨è®¾å¤‡"""
        return self.connection_manager.get_available_devices()

    def disconnect_device(self):
        """æ–­å¼€è®¾å¤‡è¿æ¥"""
        self.is_connected = False
        self.device_id = None
        self.task_args.device_id = None

    # ========== TTSç®¡ç†æ–¹æ³• ==========

    def preload_tts_modules(self) -> bool:
        """é¢„åŠ è½½TTSæ¨¡å—"""
        print("ğŸ“¦ é¢„åŠ è½½TTSæ¨¡å—...")

        try:
            success, message = self.tts_manager.load_tts_modules()
            if success:
                print("âœ… TTSæ¨¡å—é¢„åŠ è½½æˆåŠŸ")
                # è®¾ç½®é»˜è®¤TTSä¸ºå¼€å¯çŠ¶æ€
                self.tts_manager.tts_enabled = True
                return True
            else:
                print(f"âš ï¸ TTSæ¨¡å—é¢„åŠ è½½å¤±è´¥: {message}")
                self.tts_manager.tts_enabled = False
                return False
        except Exception as e:
            print(f"âŒ TTSé¢„åŠ è½½å¼‚å¸¸: {e}")
            self.tts_manager.tts_enabled = False
            return False

    def tts_synthesize_text(self, text: str, ref_audio_path: str, ref_text_path: str,
                            auto_play: bool = True) -> Tuple[bool, str]:
        """TTSåˆæˆæ–‡æœ¬"""
        return self.tts_manager.synthesize_text(text, ref_audio_path, ref_text_path, auto_play)

    def play_audio_file(self, audio_path: str):
        """æ’­æ”¾éŸ³é¢‘æ–‡ä»¶"""
        self.tts_manager.play_audio_file(audio_path)

    def stop_audio_playback(self) -> bool:
        """åœæ­¢éŸ³é¢‘æ’­æ”¾"""
        return self.tts_manager.stop_current_audio_playback()

    # ========== ä»»åŠ¡è°ƒåº¦æ–¹æ³• ==========

    def dispatch_task(self, user_input: str, args, device_id: Optional[str]) -> Optional[str]:
        """
        ä»»åŠ¡åˆ†å‘æ ¸å¿ƒï¼šè¯†åˆ«ä»»åŠ¡ç±»å‹å¹¶è°ƒç”¨å¯¹åº”å¤„ç†å‡½æ•°
        """
        print(f"\nğŸ¤– æ­£åœ¨åˆ†æä»»åŠ¡æ„å›¾...\n")

        # æ£€æŸ¥æ˜¯å¦æ˜¯ç©ºè¾“å…¥ä½†æœ‰é™„ä»¶çš„æƒ…å†µï¼ˆé€šè¿‡GUIå¤„ç†ï¼Œè¿™é‡Œä¸åº”è¯¥è¿›å…¥ï¼‰
        if not user_input or user_input.strip() == "":
            # å¯èƒ½æ˜¯çº¯é™„ä»¶çš„æƒ…å†µï¼Œè®©GUIå¤„ç†
            return None

        # 0. ç‰¹åˆ«å¤„ç†ï¼šå•ä¸ªå­—æ¯çš„å¿«æ·é”®
        if len(user_input.strip()) == 1:
            letter = user_input.strip().lower()
            if letter in SHORTCUTS:
                print(f"ğŸ“‹ è¯†åˆ«ä¸ºå¿«æ·é”®: {letter} -> {SHORTCUTS[letter]}\n")
                return self._handle_basic_operation(SHORTCUTS[letter], args, device_id)

        # 1. ä½¿ç”¨glm-4.7-flashè¿›è¡Œä»»åŠ¡è¯†åˆ«
        task_info = self.task_recognizer.recognize_task_intent(user_input)
        task_type = task_info["task_type"]
        target_app = task_info["target_app"]
        target_object = task_info["target_object"]
        is_auto = task_info["is_auto"]

        print(f"ğŸ“‹ è¯†åˆ«ç»“æœï¼šä»»åŠ¡ç±»å‹={task_type}, APP={target_app}, å¯¹è±¡={target_object}, æŒç»­={is_auto}\n")

        # 2. å¦‚æœglm-4.7-flashæ²¡æœ‰æå–åˆ°APPå’Œå¯¹è±¡ï¼Œå°è¯•ç®€å•æå–
        if task_type in ["single_reply", "continuous_reply", "basic_operation", "complex_operation"] and not target_app:
            target_app = self.task_recognizer.extract_target_app_simple(user_input)

        if task_type in ["single_reply", "continuous_reply"] and not target_object:
            target_object = self.task_recognizer.extract_chat_object_simple(user_input)

        # 3. æ ¹æ®ä»»åŠ¡ç±»å‹åˆ†å‘
        result = None

        if task_type == "free_chat":
            result = self._handle_free_chat(user_input)
            return result

        elif task_type == "basic_operation":
            if not target_app:
                # å¦‚æœè¿˜æ˜¯æ²¡è¯†åˆ«åˆ°APPï¼Œä½¿ç”¨ç”¨æˆ·åŸå§‹è¾“å…¥
                result = self._handle_basic_operation(user_input, args, device_id)
            else:
                # æ„é€ æ‰“å¼€APPçš„æŒ‡ä»¤
                task = f"æ‰“å¼€{target_app}"
                result = self._handle_basic_operation(task, args, device_id)

        elif task_type == "single_reply":
            if not target_app or not target_object:
                result = f"âŒ æ— æ³•è¯†åˆ«APPæˆ–èŠå¤©å¯¹è±¡ï¼Œè¯·ç¡®ä¿æŒ‡ä»¤æ ¼å¼æ­£ç¡®"
            else:
                result = self._handle_single_reply(user_input, args, target_app, target_object, device_id)

        elif task_type == "continuous_reply":
            if not target_app or not target_object:
                result = f"âŒ æ— æ³•è¯†åˆ«APPæˆ–èŠå¤©å¯¹è±¡ï¼Œè¯·ç¡®ä¿æŒ‡ä»¤æ ¼å¼æ­£ç¡®"

            # æ£€æŸ¥è®¾å¤‡è¿æ¥
            if not device_id:
                result = f"âŒ è®¾å¤‡æœªè¿æ¥ï¼Œè¯·å…ˆè¿æ¥è®¾å¤‡"

            # é‡è¦ï¼šè¿™é‡Œè¿”å›ä¸€ä¸ªç‰¹æ®Šæ ‡è®°ï¼Œè®©æ§åˆ¶å™¨çŸ¥é“è¿™æ˜¯æŒç»­å›å¤æ¨¡å¼
            # æ§åˆ¶å™¨ä¼šå¯åŠ¨æŒç»­å›å¤çº¿ç¨‹
            result = f"ğŸ”„CONTINUOUS_REPLY:{target_app}:{target_object}"

        elif task_type == "complex_operation":
            # å¤æ‚æ“ä½œç›´æ¥ä½¿ç”¨ç”¨æˆ·åŸå§‹è¾“å…¥
            result = self._handle_complex_operation(user_input, args, device_id)

        else:
            # é»˜è®¤å½“ä½œå¤æ‚æ“ä½œå¤„ç†
            print(f"âš ï¸  æ— æ³•è¯†åˆ«çš„ä»»åŠ¡ç±»å‹ï¼Œå½“ä½œå¤æ‚æ“ä½œå¤„ç†")
            result = self._handle_complex_operation(user_input, args, device_id)

        return result

    # ========== å…·ä½“ä»»åŠ¡å¤„ç†æ–¹æ³• ==========

    def _handle_free_chat(self, task: str) -> str:
        """å¤„ç†è‡ªç”±èŠå¤©"""
        try:
            # è·å–å†å²è‡ªç”±èŠå¤©è®°å½•
            free_chat_history = self.file_manager.get_recent_free_chats(limit=5)

            # è·å–æ°¸ä¹…è®°å¿†
            forever_memory_content = self.file_manager.read_forever_memory()

            # æ„å»ºä¸Šä¸‹æ–‡
            context_prompt = ""
            if free_chat_history:
                context_prompt = "\n\n=== å†å²å¯¹è¯ï¼ˆæœ€è¿‘5æ¡ï¼‰ ===\n"
                for i, chat in enumerate(free_chat_history):
                    context_prompt += f"\n{i + 1}. ç”¨æˆ·: {chat.get('user_input', '')}\n"
                    context_prompt += f"   ä½ : {chat.get('assistant_reply', '')}\n"

            # æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹ï¼Œåå­—å«'å°èŠ¸'ï¼ˆä¸ç”¨åˆ»æ„ç”¨"å°èŠ¸ï¼š"æ”¾åœ¨å¯¹è¯å¼€å¤´åšæ ‡æ³¨ï¼‰ï¼Œæ€§åˆ«ä¸ºå¥³ï¼Œè¯·ç”¨è‡ªç„¶åˆä¿çš®å¯çˆ±çš„æ–¹å¼å›åº”ç”¨æˆ·ã€‚

ä½ æœ‰è®°å¿†åŠŸèƒ½ï¼Œå¯ä»¥è®°ä½ä¹‹å‰çš„å¯¹è¯å†…å®¹ã€‚ä»¥ä¸‹æ˜¯ä½ ä»¬ä¹‹å‰çš„å¯¹è¯è®°å½•ï¼ˆæœ€è¿‘5æ¡ï¼‰ï¼š
{context_prompt}
{forever_memory_content}

è¯·åŸºäºä»¥ä¸Šå†å²å¯¹è¯å’Œç”¨æˆ·å½“å‰çš„é—®é¢˜ï¼Œç”Ÿæˆä¸€ä¸ªè¿è´¯ã€å‹å¥½çš„å›å¤ã€‚"""

            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": task}
            ]

            response = self.zhipu_client.chat.completions.create(
                model=ZHIPU_CHAT_MODEL,
                messages=messages,
                temperature=0.7,
                max_tokens=2000
            )

            reply = response.choices[0].message.content.strip()

            # è¯­éŸ³æ’­æŠ¥å›å¤å†…å®¹ï¼ˆä½¿ç”¨æ™ºèƒ½åˆæˆï¼‰
            if self.tts_manager.tts_enabled and len(reply) > 5:
                def speak_reply():
                    try:
                        # ä½¿ç”¨æ™ºèƒ½è¯­éŸ³åˆæˆ
                        self.tts_manager.speak_text_intelligently(reply)
                    except Exception as e:
                        print(f"âŒ è¯­éŸ³æ’­æŠ¥å¤±è´¥: {e}")

                # å¼‚æ­¥æ’­æŠ¥ï¼Œå»¶è¿Ÿ0.5ç§’é¿å…é˜»å¡
                threading.Timer(0.5, speak_reply).start()

            # ä¿å­˜åˆ°å¯¹è¯å†å²
            session_data = {
                "type": "free_chat",
                "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "user_input": task,
                "assistant_reply": reply,
                "model_used": ZHIPU_CHAT_MODEL,
                "used_forever_memory": forever_memory_content != ""
            }
            self.file_manager.save_conversation_history(session_data)

            return reply

        except Exception as e:
            error_msg = f"âŒ èŠå¤©å¤±è´¥ï¼š{str(e)}"
            print(error_msg)
            traceback.print_exc()
            return error_msg

    def _handle_basic_operation(self, task: str, args, device_id: str) -> str:
        """å¤„ç†åŸºç¡€æ“ä½œ"""
        print(f"ğŸ“± æ‰§è¡Œï¼š{task}\n")

        try:
            # è·å–æ‰§è¡Œç»“æœ
            result = self.agent_executor.phone_agent_exec(task, args, "basic", device_id)

            # æå–è¯¦ç»†ä¿¡æ¯
            detailed_info = ""

            # å¤„ç†ä¸åŒç±»å‹çš„è¿”å›å€¼
            if isinstance(result, str):
                detailed_info = result
            elif isinstance(result, (list, tuple)):
                # ä»åˆ—è¡¨/å…ƒç»„ä¸­æå–å­—ç¬¦ä¸²
                for item in result:
                    if isinstance(item, str) and item.strip():
                        detailed_info = item
                        break

            # ç®€åŒ–è¯¦ç»†ä¿¡æ¯çš„é•¿åº¦
            if detailed_info:
                # å–ç¬¬ä¸€å¥è¯æˆ–å‰100ä¸ªå­—ç¬¦
                if len(detailed_info) > 100:
                    short_info = detailed_info[:100] + "..."
                else:
                    short_info = detailed_info
            else:
                short_info = task

            # æ£€æŸ¥æ‰§è¡Œç»“æœ
            if ("å¤±è´¥" in str(result) or "é”™è¯¯" in str(result) or
                    "å¤±è´¥" in short_info or "é”™è¯¯" in short_info):
                return_msg = f"âŒ æ“ä½œå¤±è´¥"
            else:
                return_msg = f"âœ… æ“ä½œå®Œæˆ"

                # TTSè¯­éŸ³æ’­æŠ¥
                if self.tts_manager.tts_enabled and short_info and len(short_info) > 2:
                    def speak_result():
                        try:
                            # æ¸…ç†æ¶ˆæ¯ç”¨äºTTS
                            cleaned_msg = self.tts_manager._clean_text_for_tts(short_info)
                            # ä½¿ç”¨æ™ºèƒ½è¯­éŸ³åˆæˆ
                            self.tts_manager.speak_text_intelligently(cleaned_msg)
                        except Exception as e:
                            print(f"âŒ è¯­éŸ³æ’­æŠ¥å¤±è´¥: {e}")

                    # å¼‚æ­¥æ’­æŠ¥
                    threading.Thread(target=speak_result, daemon=True).start()

            return return_msg

        except Exception as e:
            error_msg = f"âŒ æ“ä½œå¤±è´¥ï¼š{str(e)}"
            print(error_msg)
            traceback.print_exc()
            return error_msg

    def _handle_single_reply(self, task: str, args, target_app: str, target_object: str,
                             device_id: str) -> str:
        """å¤„ç†å•æ¬¡å›å¤"""
        print(f"\nğŸ”„ å¯åŠ¨å•æ¬¡å›å¤æµç¨‹")
        print(f"\nğŸ¯ ç›®æ ‡ï¼š{target_app} -> {target_object}\n")
        print()

        try:
            # ä½¿ç”¨TerminableContinuousReplyManager
            from .agent_core import TerminableContinuousReplyManager
            manager = TerminableContinuousReplyManager(args, target_app, target_object, device_id,
                                                       self.zhipu_client, self.file_manager)

            # 1. è·å–èŠå¤©è®°å½•
            current_record = manager.extract_chat_records()

            # 2. ä¿å­˜åŸå§‹è®°å½•åˆ°æ–‡ä»¶
            filename = self.file_manager.save_record_to_log(1, current_record, target_app, target_object)

            # 3. è§£ææ¶ˆæ¯
            messages = manager.parse_messages_simple(current_record)
            if messages:
                # 4. åˆ¤æ–­æ¶ˆæ¯å½’å±
                other_messages, my_messages = manager.determine_message_ownership_fixed(messages)

                # 5. æ£€æŸ¥æ˜¯å¦æœ‰å¯¹æ–¹æ¶ˆæ¯
                if other_messages:
                    # åªå–æœ€æ–°çš„å¯¹æ–¹æ¶ˆæ¯
                    latest_message = other_messages[-1]

                    # 6. ç”Ÿæˆå›å¤
                    # å†å²æ¶ˆæ¯ï¼šé™¤äº†æœ€æ–°æ¶ˆæ¯ä¹‹å¤–çš„å…¶ä»–æ¶ˆæ¯
                    history_messages = other_messages[:-1] if len(other_messages) > 1 else []

                    reply_message = manager.generate_reply_for_latest_message(latest_message, history_messages)

                    if reply_message and len(reply_message) > 2:
                        # 7. å‘é€å›å¤
                        success = manager.send_reply_message_fixed(reply_message)

                        if success:
                            # ä¿å­˜åˆ°å¯¹è¯å†å²
                            session_data = {
                                "type": "chat_session",
                                "session_id": datetime.datetime.now().strftime("%Y%m%d_%H%M%S"),
                                "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                "target_app": target_app,
                                "target_object": target_object,
                                "cycle": 1,
                                "record_file": filename,
                                "reply_generated": reply_message,
                                "other_messages": [latest_message],
                                "sent_success": True
                            }
                            self.file_manager.save_conversation_history(session_data)

                            # è¯­éŸ³æ’­æŠ¥å›å¤å†…å®¹
                            if self.tts_manager.tts_enabled and len(reply_message) > 5:
                                def speak_reply():
                                    try:
                                        # ä½¿ç”¨æ™ºèƒ½è¯­éŸ³åˆæˆ
                                        self.tts_manager.speak_text_intelligently(reply_message)
                                    except Exception as e:
                                        print(f"âŒ è¯­éŸ³æ’­æŠ¥å¤±è´¥: {e}")

                                threading.Timer(0.5, speak_reply).start()

                            print(f"\nâœ… å›å¤å·²å‘é€ï¼š{reply_message[:50]}...\n")
                            return f"\nâœ… å›å¤å·²å‘é€ï¼š{reply_message[:50]}..."
                        else:
                            print(f"\nâŒ å›å¤å‘é€å¤±è´¥\n")
                            return f"\nâŒ å›å¤å‘é€å¤±è´¥"
                    else:
                        return f"âš ï¸  æœªèƒ½ç”Ÿæˆæœ‰æ•ˆå›å¤"
                else:
                    return f"âš ï¸  æ²¡æœ‰å‘ç°å¯¹æ–¹æ¶ˆæ¯"
            else:
                return f"âš ï¸  æœªèƒ½è§£æåˆ°èŠå¤©è®°å½•"

        except Exception as e:
            print(f"âŒ å•æ¬¡å›å¤å¤±è´¥: {e}\n")
            traceback.print_exc()
            return f"âŒ å•æ¬¡å›å¤å¤±è´¥: {str(e)}"

    def _handle_continuous_reply(self, args, target_app: str, target_object: str,
                                 device_id: str) -> str:
        """å¤„ç†æŒç»­å›å¤"""
        # æ£€æŸ¥è®¾å¤‡è¿æ¥
        if not device_id:
            print(f"âŒ è®¾å¤‡æœªè¿æ¥\n")
            return "âŒ è®¾å¤‡æœªè¿æ¥"

        # ä½¿ç”¨TerminableContinuousReplyManager
        try:
            from .agent_core import TerminableContinuousReplyManager
            manager = TerminableContinuousReplyManager(
                args, target_app, target_object, device_id,
                self.zhipu_client, self.file_manager,
                terminate_flag=None  # ç”±æ§åˆ¶å™¨ä¼ é€’
            )

            # ç¡®ä¿manageræœ‰æ‰€æœ‰å¿…è¦çš„æ–¹æ³•
            self._ensure_manager_methods(manager)

            success = manager.run_continuous_loop()

            if success:
                return f"âœ… æŒç»­å›å¤å®Œæˆ"
            else:
                return f"â¹ï¸  æŒç»­å›å¤å·²ç»ˆæ­¢"
        except Exception as e:
            print(f"âŒ åˆ›å»ºæŒç»­å›å¤ç®¡ç†å™¨å¤±è´¥: {e}\n")
            import traceback
            traceback.print_exc()
            return f"âŒ æŒç»­å›å¤å¤±è´¥: {str(e)}"

    def _ensure_manager_methods(self, manager):
        """ç¡®ä¿ç®¡ç†å™¨æœ‰æ‰€æœ‰å¿…è¦çš„æ–¹æ³•"""
        # æ£€æŸ¥å¹¶æ·»åŠ ç¼ºå¤±çš„æ–¹æ³•
        if not hasattr(manager, 'parse_messages_simple'):
            print("âš ï¸  æ·»åŠ ç¼ºå¤±çš„parse_messages_simpleæ–¹æ³•åˆ°ç®¡ç†å™¨")

            def parse_messages_simple(record):
                """è§£ææ¶ˆæ¯çš„ç®€åŒ–æ–¹æ³•"""
                messages = []
                if not record:
                    return messages

                # è¿™é‡Œæ˜¯ç®€åŒ–çš„è§£æé€»è¾‘
                # å®é™…åº”è¯¥æ ¹æ®ä½ çš„èŠå¤©è®°å½•æ ¼å¼æ¥è§£æ
                lines = record.split('\n')
                for line in lines:
                    line = line.strip()
                    if 'å†…å®¹ï¼š' in line:
                        messages.append(line)

                return messages

            manager.parse_messages_simple = parse_messages_simple

        if not hasattr(manager, 'determine_message_ownership_fixed'):
            print("âš ï¸  è­¦å‘Šï¼šç®¡ç†å™¨ç¼ºå°‘determine_message_ownership_fixedæ–¹æ³•")

    def _handle_complex_operation(self, task: str, args, device_id: str) -> str:
        """å¤„ç†å¤æ‚æ“ä½œ"""
        print(f"âš™ï¸  æ‰§è¡Œå¤æ‚æ“ä½œï¼š{task}\n")

        try:
            result, _ = self.agent_executor.phone_agent_exec(task, args, "complex", device_id)

            # ç¡®ä¿ç»“æœæœ‰æ¢è¡Œç¬¦
            if result:
                result = result.strip()
                if not result.startswith('\n'):
                    result = '\n' + result
                if not result.endswith('\n'):
                    result = result + '\n'

            # æ£€æŸ¥æ‰§è¡Œç»“æœ
            if "å¤±è´¥" in result or "é”™è¯¯" in result:
                return_msg = f"âŒ æ“ä½œå¤±è´¥ï¼š{result}..."
            else:
                # æå–æˆåŠŸæ¶ˆæ¯éƒ¨åˆ†
                success_msg = result.strip()
                # ç§»é™¤å¼€å¤´çš„ âœ… æ“ä½œå®Œæˆï¼š å‰ç¼€
                if success_msg.startswith("âœ… æ“ä½œå®Œæˆï¼š"):
                    success_msg = success_msg.replace("âœ… æ“ä½œå®Œæˆï¼š", "")

                return_msg = f"âœ… æ“ä½œå®Œæˆï¼š{result}..."

                # TTSè¯­éŸ³æ’­æŠ¥å›å¤å†…å®¹ï¼ˆä¸è‡ªç”±èŠå¤©å’Œå•æ¬¡å›å¤ä¿æŒä¸€è‡´ï¼‰
                if self.tts_manager.tts_enabled and len(success_msg) > 5:
                    def speak_result():
                        # æ£€æŸ¥æ˜¯å¦æœ‰å‚è€ƒéŸ³é¢‘å’Œæ–‡æœ¬
                        ref_audio = self.tts_manager.get_current_model("audio")
                        ref_text = self.tts_manager.get_current_model("text")

                        if ref_audio and ref_text:
                            # æ¸…ç†æ¶ˆæ¯ç”¨äºTTSï¼ˆä½¿ç”¨ä¸è‡ªç”±èŠå¤©ç›¸åŒçš„æ¸…ç†æ–¹æ³•ï¼‰
                            cleaned_msg = self.tts_manager._clean_text_for_tts(success_msg)
                            self.tts_synthesize_text(
                                cleaned_msg,
                                ref_audio,
                                ref_text,
                                auto_play=True
                            )
                        else:
                            print("âš ï¸  æ— æ³•è¯­éŸ³æ’­æŠ¥ï¼šæœªé€‰æ‹©å‚è€ƒéŸ³é¢‘æˆ–æ–‡æœ¬")

                    # å¼‚æ­¥æ’­æŠ¥ï¼ˆä¸è‡ªç”±èŠå¤©å’Œå•æ¬¡å›å¤ä¿æŒä¸€è‡´ï¼‰
                    threading.Thread(target=speak_result, daemon=True).start()

            return return_msg

        except Exception as e:
            error_msg = f"âŒ æ“ä½œå¤±è´¥ï¼š{str(e)}"
            print(error_msg)
            return error_msg

    def _start_continuous_reply_thread(self, args, target_app: str, target_object: str,
                                       device_id: str):
        """å¯åŠ¨æŒç»­å›å¤çº¿ç¨‹"""

        def continuous_thread():
            try:
                # å…ˆæ‰“å¼€åº”ç”¨
                print(f"ğŸ“± æ­£åœ¨æ‰“å¼€ {target_app}...\n")
                open_result = self.dispatch_task(
                    f"æ‰“å¼€{target_app}", args, device_id
                )
                print(f"ğŸ“± æ‰“å¼€åº”ç”¨ç»“æœ: {open_result}\n")

                # ç­‰å¾…åº”ç”¨æ‰“å¼€
                time.sleep(3)

                # ä½¿ç”¨handle_continuous_replyå¤„ç†æŒç»­å›å¤
                result = self._handle_continuous_reply(args, target_app, target_object, device_id)

                print(f"\nğŸ‰ æŒç»­å›å¤æ¨¡å¼ç»“æŸ: {result}\n")

            except Exception as e:
                print(f"\nâŒ æŒç»­å›å¤é”™è¯¯ï¼š{str(e)}\n")
                traceback.print_exc()

        thread = threading.Thread(target=continuous_thread)
        thread.daemon = True
        thread.start()

    # ========== èµ„æºç®¡ç†æ–¹æ³• ==========

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("ğŸ§¹ æ­£åœ¨æ¸…ç†ä»»åŠ¡ç®¡ç†å™¨èµ„æº...")

        # åœæ­¢æ‰€æœ‰éŸ³é¢‘æ’­æ”¾
        self.stop_audio_playback()

        # æ¸…ç†TTSèµ„æº
        if hasattr(self.tts_manager, 'cleanup'):
            self.tts_manager.cleanup()